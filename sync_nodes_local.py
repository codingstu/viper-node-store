#!/usr/bin/env python3
"""
ç›´æ¥åŒæ­¥è„šæœ¬ - ä»æœ¬åœ° nodes.json åŒæ­¥åˆ° Supabase
"""

import json
import os
from datetime import datetime
from pathlib import Path

# Supabase é…ç½® (ä»ç¯å¢ƒå˜é‡è¯»å–)
SUPABASE_URL = os.environ.get("SUPABASE_URL", "https://hnlkwtkxbqiakeyienok.supabase.co")
# ä½¿ç”¨ service_role key ç»•è¿‡ RLS é™åˆ¶
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_ROLE_KEY") or os.environ.get("SUPABASE_KEY")
if not SUPABASE_KEY:
    SUPABASE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImhubGt3dGt4YnFpYWtleWllbm9rIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2NjkwNDA1OSwiZXhwIjoyMDgyNDgwMDU5fQ.VXnH4suGKI6wBLCUi5cHYHO27PUJE_I-iPS3HAhYtSk"

def sync_nodes_from_file(json_file_path):
    """
    ä»æœ¬åœ° JSON æ–‡ä»¶åŒæ­¥èŠ‚ç‚¹åˆ° Supabase
    """
    print("\n" + "="*70)
    print("ğŸ”„ å¼€å§‹ä»æœ¬åœ°æ–‡ä»¶åŒæ­¥æ•°æ®åˆ° Supabase")
    print("="*70 + "\n")

    # è¯»å–æœ¬åœ° JSON æ–‡ä»¶
    if not Path(json_file_path).exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        return False

    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            nodes = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return False

    if not isinstance(nodes, list) or len(nodes) == 0:
        print(f"âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯æˆ–ä¸ºç©º")
        return False

    print(f"âœ… æˆåŠŸåŠ è½½ {len(nodes)} ä¸ªèŠ‚ç‚¹")
    print(f"   æ–‡ä»¶: {json_file_path}")
    print()

    # è¿æ¥ Supabase
    try:
        from supabase import create_client
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        print("âœ… å·²è¿æ¥åˆ° Supabase")
    except Exception as e:
        print(f"âŒ Supabase è¿æ¥å¤±è´¥: {e}")
        return False

    # å‡†å¤‡æ•°æ®
    data = []
    seen_ids = set()

    for i, node in enumerate(nodes):
        # âœ… ä¿®å¤ï¼šåªåŒæ­¥å·²æµ‹é€Ÿçš„èŠ‚ç‚¹ï¼ˆlatency_ms ä¸ä¸º 9999ï¼‰
        latency = node.get("latency_ms", 9999)
        if latency == 9999:
            # è·³è¿‡æœªæµ‹é€Ÿçš„èŠ‚ç‚¹
            continue
        
        # æ„é€ å”¯ä¸€ID
        node_id = f"{node.get('host', 'unknown')}:{node.get('port', 'unknown')}"

        # è·³è¿‡é‡å¤
        if node_id in seen_ids:
            print(f"âš ï¸ è·³è¿‡é‡å¤: {node_id}")
            continue

        seen_ids.add(node_id)

        # è·å– link å­—æ®µ (ä¼˜å…ˆä»èŠ‚ç‚¹æœ¬èº«ï¼Œå¦åˆ™ä¸ºç©º)
        link = node.get("link", "")
        
        data.append({
            "id": node_id,
            "content": node,
            "link": link,
            "is_free": len(data) < 15,  # å‰ 15 ä¸ªå…è´¹
            "speed": int(float(node.get("speed", 0))),
            "latency": int(latency),
            "updated_at": datetime.now().isoformat()
        })

    if not data:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®éœ€è¦ä¿å­˜")
        return False

    # æ‰¹é‡ä¿å­˜
    batch_size = 50
    total_saved = 0
    failed_batches = []

    print(f"\nğŸ“¤ å¼€å§‹ä¿å­˜ {len(data)} æ¡æ•°æ®åˆ° Supabase...\n")

    for i in range(0, len(data), batch_size):
        batch = data[i:i + batch_size]
        batch_num = i // batch_size + 1

        try:
            supabase.table("nodes").upsert(batch).execute()
            total_saved += len(batch)
            
            # æ˜¾ç¤ºä¿å­˜ç»“æœ
            for node_data in batch:
                node_id = node_data["id"]
                link = node_data["link"]
                link_status = "âœ… æœ‰" if link else "âŒ æ— "
                print(f"   {batch_num}.{batch[0]['id']} - {link_status} link å­—æ®µ")
            
            print(f"âœ… æ‰¹æ¬¡ {batch_num}: ä¿å­˜ {len(batch)} æ¡")

        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡ {batch_num} å¤±è´¥: {e}")
            failed_batches.append(batch_num)

    print()
    print("="*70)
    if failed_batches:
        print(f"âš ï¸ å®Œæˆ! ä¿å­˜ {total_saved}/{len(data)} æ¡æ•°æ® (å¤±è´¥æ‰¹æ¬¡: {failed_batches})")
    else:
        print(f"âœ… å®Œæˆ! æˆåŠŸä¿å­˜ {total_saved}/{len(data)} æ¡æ•°æ®åˆ° Supabase")
    print("="*70 + "\n")

    return True


if __name__ == "__main__":
    # æ”¯æŒå¤šä¸ªè·¯å¾„
    paths = [
        "public/nodes.json",
        "/Users/ikun/study/Learning/viper-node-store/public/nodes.json",
        "/Users/ikun/study/Learning/SpiderFlow/backend/verified_nodes.json"
    ]

    success = False
    for path in paths:
        if Path(path).exists():
            success = sync_nodes_from_file(path)
            if success:
                break

    if not success:
        print(f"âŒ æ— æ³•ä»ä»»ä½•æ¥æºåŒæ­¥æ•°æ®")
        print(f"   å°è¯•çš„è·¯å¾„: {', '.join(paths)}")
