#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
=== viper-node-store è½»é‡çº§èŠ‚ç‚¹å¥åº·æ£€æµ‹æ¨¡å— ===

åŠŸèƒ½:
1. TCP è¿æ¥æµ‹è¯• - æ£€æµ‹èŠ‚ç‚¹ç«¯å£æ˜¯å¦å¯è¾¾
2. HTTP ä»£ç†æµ‹è¯• - é€šè¿‡ä»£ç†è¯·æ±‚æµ‹è¯• URL éªŒè¯ä»£ç†åŠŸèƒ½
3. å¤±è´¥é‡è¯•æœºåˆ¶ - æ£€æµ‹å¤±è´¥è‡ªåŠ¨é‡è¯•2æ¬¡
4. çŠ¶æ€æ›´æ–° - å°†æ£€æµ‹ç»“æœå†™å…¥ Supabase

æ£€æµ‹çŠ¶æ€:
- online: èŠ‚ç‚¹æ­£å¸¸å¯ç”¨
- offline: èŠ‚ç‚¹ä¸å¯ç”¨ï¼ˆTCPæˆ–HTTPæµ‹è¯•å‡å¤±è´¥ï¼‰
- suspect: å¯ç–‘èŠ‚ç‚¹ï¼ˆTCPé€šä½†HTTPå¤±è´¥ï¼‰

é€‚ç”¨äº Vercel Serverless ç¯å¢ƒï¼ˆè½»é‡çº§ï¼Œæ— å¤–éƒ¨ä¾èµ–ï¼‰
"""

import asyncio
import aiohttp
import socket
import logging
from typing import List, Dict, Optional, Tuple
from datetime import datetime
from dataclasses import dataclass
from enum import Enum
import os

logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)


class NodeStatus(str, Enum):
    """èŠ‚ç‚¹çŠ¶æ€æšä¸¾"""
    ONLINE = "online"
    OFFLINE = "offline"
    SUSPECT = "suspect"
    UNKNOWN = "unknown"


@dataclass
class HealthCheckResult:
    """å¥åº·æ£€æµ‹ç»“æœ"""
    node_id: str
    host: str
    port: int
    status: NodeStatus
    tcp_ok: bool
    http_ok: bool
    latency_ms: Optional[int] = None
    error_message: Optional[str] = None
    retry_count: int = 0
    checked_at: str = ""


class LightweightHealthChecker:
    """è½»é‡çº§å¥åº·æ£€æµ‹å™¨ï¼ˆæ— å¤–éƒ¨ä¾èµ–ï¼‰"""
    
    def __init__(
        self,
        tcp_timeout: float = 5.0,
        http_timeout: float = 10.0,
        max_retries: int = 2,
        max_concurrent: int = 20
    ):
        """
        åˆå§‹åŒ–æ£€æµ‹å™¨
        
        Args:
            tcp_timeout: TCP è¿æ¥è¶…æ—¶ï¼ˆç§’ï¼‰
            http_timeout: HTTP è¯·æ±‚è¶…æ—¶ï¼ˆç§’ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
            max_concurrent: æœ€å¤§å¹¶å‘æ•°
        """
        self.tcp_timeout = tcp_timeout
        self.http_timeout = http_timeout
        self.max_retries = max_retries
        self.max_concurrent = max_concurrent
        self.test_urls = [
            "http://www.gstatic.com/generate_204",
            "http://cp.cloudflare.com/",
            "http://connectivitycheck.platform.hicloud.com/generate_204"
        ]
    
    async def check_tcp_connection(self, host: str, port: int) -> Tuple[bool, Optional[int], Optional[str]]:
        """
        TCP è¿æ¥æµ‹è¯•
        
        Returns:
            (æˆåŠŸ, å»¶è¿Ÿæ¯«ç§’, é”™è¯¯ä¿¡æ¯)
        """
        try:
            start_time = asyncio.get_event_loop().time()
            
            # ä½¿ç”¨ asyncio çš„æ–¹å¼è¿›è¡Œ TCP è¿æ¥æµ‹è¯•
            future = asyncio.open_connection(host, port)
            reader, writer = await asyncio.wait_for(future, timeout=self.tcp_timeout)
            
            latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
            
            # å…³é—­è¿æ¥
            writer.close()
            await writer.wait_closed()
            
            return True, latency_ms, None
            
        except asyncio.TimeoutError:
            return False, None, "TCP connection timeout"
        except ConnectionRefusedError:
            return False, None, "Connection refused"
        except OSError as e:
            return False, None, f"OS error: {str(e)[:50]}"
        except Exception as e:
            return False, None, f"TCP error: {str(e)[:50]}"
    
    async def check_http_connectivity(self, host: str, port: int, protocol: str = "http") -> Tuple[bool, Optional[int], Optional[str]]:
        """
        HTTP è¿é€šæ€§æµ‹è¯•ï¼ˆç›´æ¥æµ‹è¯•èŠ‚ç‚¹çš„ HTTP å“åº”ï¼‰
        
        å¯¹äºä»£ç†èŠ‚ç‚¹ï¼Œæˆ‘ä»¬æµ‹è¯•æ˜¯å¦èƒ½é€šè¿‡ä»£ç†è®¿é—®æµ‹è¯• URL
        ç”±äºæ²¡æœ‰ä»£ç†å®¢æˆ·ç«¯ï¼Œè¿™é‡Œç®€åŒ–ä¸ºç›´æ¥æµ‹è¯•èŠ‚ç‚¹çš„ HTTP æœåŠ¡
        
        Returns:
            (æˆåŠŸ, å»¶è¿Ÿæ¯«ç§’, é”™è¯¯ä¿¡æ¯)
        """
        # å¯¹äºé HTTP åè®®çš„èŠ‚ç‚¹ï¼Œåªåš TCP æµ‹è¯•
        if protocol.lower() not in ['http', 'https', 'socks5', 'socks']:
            # å¯¹äº vmess/vless/trojan/ss ç­‰åè®®ï¼ŒTCP é€šå°±è®¤ä¸ºåŸºæœ¬å¯ç”¨
            return True, 0, None
        
        try:
            start_time = asyncio.get_event_loop().time()
            
            # æ„å»ºæµ‹è¯• URL
            if protocol.lower() in ['http', 'https']:
                test_url = f"{protocol}://{host}:{port}/"
            else:
                # å¯¹äº socks åè®®ï¼Œæ— æ³•ç›´æ¥æµ‹è¯•ï¼Œæ ‡è®°ä¸ºé€šè¿‡
                return True, 0, None
            
            async with aiohttp.ClientSession() as session:
                async with session.head(
                    test_url,
                    timeout=aiohttp.ClientTimeout(total=self.http_timeout),
                    allow_redirects=False,
                    ssl=False
                ) as resp:
                    latency_ms = int((asyncio.get_event_loop().time() - start_time) * 1000)
                    
                    # ä»»ä½•å“åº”éƒ½è¯´æ˜èŠ‚ç‚¹æ˜¯æ´»çš„
                    return True, latency_ms, None
                    
        except asyncio.TimeoutError:
            return False, None, "HTTP timeout"
        except aiohttp.ClientError as e:
            return False, None, f"HTTP error: {str(e)[:50]}"
        except Exception as e:
            return False, None, f"HTTP error: {str(e)[:50]}"
    
    async def check_node(self, node: Dict) -> HealthCheckResult:
        """
        æ£€æµ‹å•ä¸ªèŠ‚ç‚¹
        
        Args:
            node: èŠ‚ç‚¹æ•°æ®ï¼Œéœ€è¦åŒ…å« host, port, protocol
            
        Returns:
            æ£€æµ‹ç»“æœ
        """
        node_id = node.get("id", "")
        host = node.get("host", "")
        port = node.get("port", 0)
        protocol = node.get("protocol", "unknown")
        
        if not host or not port:
            return HealthCheckResult(
                node_id=node_id,
                host=host,
                port=port,
                status=NodeStatus.OFFLINE,
                tcp_ok=False,
                http_ok=False,
                error_message="Invalid host or port",
                checked_at=datetime.utcnow().isoformat()
            )
        
        # å¸¦é‡è¯•çš„æ£€æµ‹
        tcp_ok = False
        http_ok = False
        latency_ms = None
        error_message = None
        retry_count = 0
        
        for attempt in range(self.max_retries + 1):
            # 1. TCP æ£€æµ‹
            tcp_ok, tcp_latency, tcp_error = await self.check_tcp_connection(host, port)
            
            if tcp_ok:
                latency_ms = tcp_latency
                
                # 2. HTTP æ£€æµ‹ï¼ˆä»…å¯¹æ”¯æŒçš„åè®®ï¼‰
                http_ok, http_latency, http_error = await self.check_http_connectivity(
                    host, port, protocol
                )
                
                if http_ok:
                    # æ£€æµ‹æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                    break
                else:
                    error_message = http_error
            else:
                error_message = tcp_error
            
            retry_count = attempt
            
            # å¦‚æœå¤±è´¥ä¸”è¿˜æœ‰é‡è¯•æœºä¼šï¼Œç­‰å¾…ä¸€å°æ®µæ—¶é—´
            if attempt < self.max_retries:
                await asyncio.sleep(0.5)
        
        # ç¡®å®šæœ€ç»ˆçŠ¶æ€
        if tcp_ok and http_ok:
            status = NodeStatus.ONLINE
        elif tcp_ok and not http_ok:
            # TCP é€šä½† HTTP ä¸é€šï¼Œå¯èƒ½æ˜¯åè®®é—®é¢˜ï¼Œæ ‡è®°ä¸ºå¯ç–‘ä½†ä¸ä¸‹çº¿
            # å¯¹äº vmess/vless/trojan ç­‰åè®®ï¼ŒTCP é€šå°±è®¤ä¸ºåœ¨çº¿
            if protocol.lower() in ['vmess', 'vless', 'trojan', 'ss', 'shadowsocks', 'ssr']:
                status = NodeStatus.ONLINE
            else:
                status = NodeStatus.SUSPECT
        else:
            status = NodeStatus.OFFLINE
        
        return HealthCheckResult(
            node_id=node_id,
            host=host,
            port=port,
            status=status,
            tcp_ok=tcp_ok,
            http_ok=http_ok,
            latency_ms=latency_ms,
            error_message=error_message,
            retry_count=retry_count,
            checked_at=datetime.utcnow().isoformat()
        )
    
    async def check_nodes_batch(self, nodes: List[Dict]) -> List[HealthCheckResult]:
        """
        æ‰¹é‡æ£€æµ‹èŠ‚ç‚¹
        
        Args:
            nodes: èŠ‚ç‚¹åˆ—è¡¨
            
        Returns:
            æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        semaphore = asyncio.Semaphore(self.max_concurrent)
        
        async def check_with_semaphore(node: Dict) -> HealthCheckResult:
            async with semaphore:
                return await self.check_node(node)
        
        tasks = [check_with_semaphore(node) for node in nodes]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # å¤„ç†å¼‚å¸¸
        final_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                node = nodes[i]
                final_results.append(HealthCheckResult(
                    node_id=node.get("id", ""),
                    host=node.get("host", ""),
                    port=node.get("port", 0),
                    status=NodeStatus.UNKNOWN,
                    tcp_ok=False,
                    http_ok=False,
                    error_message=f"Check exception: {str(result)[:50]}",
                    checked_at=datetime.utcnow().isoformat()
                ))
            else:
                final_results.append(result)
        
        return final_results


class SupabaseHealthUpdater:
    """Supabase å¥åº·çŠ¶æ€æ›´æ–°å™¨"""
    
    def __init__(self, supabase_url: str = None, supabase_key: str = None):
        self.supabase_url = supabase_url or os.environ.get("SUPABASE_URL", "")
        self.supabase_key = supabase_key or os.environ.get("SUPABASE_KEY", "")
    
    async def get_nodes_for_check(self, limit: int = 100) -> List[Dict]:
        """
        ä» Supabase è·å–éœ€è¦æ£€æµ‹çš„èŠ‚ç‚¹
        
        Args:
            limit: æ¯æ¬¡æ£€æµ‹çš„èŠ‚ç‚¹æ•°é‡ï¼ˆVercel é™åˆ¶ï¼‰
            
        Returns:
            èŠ‚ç‚¹åˆ—è¡¨
        """
        if not self.supabase_url or not self.supabase_key:
            logger.error("Supabase credentials not configured")
            return []
        
        try:
            # æŸ¥è¯¢éœ€è¦æ£€æµ‹çš„èŠ‚ç‚¹
            # ä¼˜å…ˆæ£€æµ‹ï¼š1) ä»æœªæ£€æµ‹è¿‡çš„ 2) æœ€ä¹…æœªæ£€æµ‹çš„
            url = f"{self.supabase_url}/rest/v1/nodes"
            params = {
                "select": "id,content,status,last_health_check",
                "order": "last_health_check.asc.nullsfirst",
                "limit": str(limit)
            }
            
            headers = {
                "apikey": self.supabase_key,
                "Authorization": f"Bearer {self.supabase_key}",
                "Content-Type": "application/json"
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params, headers=headers, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                    if resp.status == 200:
                        rows = await resp.json()
                        logger.info(f"æŸ¥è¯¢åˆ° {len(rows)} æ¡è®°å½•")
                        
                        if not rows:
                            logger.warning("Supabase è¿”å›ç©ºç»“æœ")
                            return []
                        
                        nodes = []
                        for row in rows:
                            try:
                                # content å­—æ®µæ˜¯ JSONBï¼ŒåŒ…å«èŠ‚ç‚¹ä¿¡æ¯
                                content = row.get("content", {})
                                if isinstance(content, str):
                                    import json
                                    content = json.loads(content)
                                
                                # æå–èŠ‚ç‚¹å…³é”®ä¿¡æ¯
                                host = content.get("host") or row.get("host")
                                port = content.get("port") or row.get("port")
                                
                                if not host or not port:
                                    logger.warning(f"èŠ‚ç‚¹ {row.get('id')} ç¼ºå°‘ host/portï¼Œè·³è¿‡")
                                    continue
                                
                                nodes.append({
                                    "id": row.get("id"),
                                    "host": str(host),
                                    "port": int(port),
                                    "protocol": content.get("protocol") or row.get("protocol", "unknown"),
                                    "name": content.get("name", ""),
                                    "current_status": row.get("status", "unknown")
                                })
                            except Exception as e:
                                logger.error(f"è§£æèŠ‚ç‚¹ {row.get('id')} å¤±è´¥: {e}")
                                continue
                        
                        logger.info(f"æˆåŠŸè§£æ {len(nodes)} ä¸ªèŠ‚ç‚¹")
                        return nodes
                    else:
                        logger.error(f"Failed to fetch nodes: HTTP {resp.status}")
                        return []
        except Exception as e:
            logger.error(f"Error fetching nodes: {e}")
            return []
    
    async def update_node_status(self, results: List[HealthCheckResult]) -> Tuple[int, int]:
        """
        æ›´æ–°èŠ‚ç‚¹çŠ¶æ€åˆ° Supabase
        
        Args:
            results: æ£€æµ‹ç»“æœåˆ—è¡¨
            
        Returns:
            (æˆåŠŸæ•°, å¤±è´¥æ•°)
        """
        if not self.supabase_url or not self.supabase_key:
            logger.error("Supabase credentials not configured")
            return 0, len(results)
        
        success_count = 0
        fail_count = 0
        
        headers = {
            "apikey": self.supabase_key,
            "Authorization": f"Bearer {self.supabase_key}",
            "Content-Type": "application/json",
            "Prefer": "return=minimal"
        }
        
        async with aiohttp.ClientSession() as session:
            for result in results:
                if not result.node_id:
                    fail_count += 1
                    continue
                
                try:
                    url = f"{self.supabase_url}/rest/v1/nodes?id=eq.{result.node_id}"
                    
                    update_data = {
                        "status": result.status.value,
                        "last_health_check": result.checked_at,
                        "health_latency": result.latency_ms
                    }
                    
                    async with session.patch(url, json=update_data, headers=headers, timeout=aiohttp.ClientTimeout(total=5)) as resp:
                        if resp.status in [200, 204]:
                            success_count += 1
                        else:
                            fail_count += 1
                            logger.warning(f"Failed to update node {result.node_id}: HTTP {resp.status}")
                            
                except Exception as e:
                    fail_count += 1
                    logger.error(f"Error updating node {result.node_id}: {e}")
        
        return success_count, fail_count


async def run_health_check(batch_size: int = 50) -> Dict:
    """
    æ‰§è¡Œå¥åº·æ£€æµ‹çš„ä¸»å‡½æ•°
    
    Args:
        batch_size: æ¯æ‰¹æ£€æµ‹çš„èŠ‚ç‚¹æ•°é‡
        
    Returns:
        æ£€æµ‹ç»“æœç»Ÿè®¡
    """
    logger.info(f"ğŸ¥ å¼€å§‹å¥åº·æ£€æµ‹ (batch_size={batch_size})")
    start_time = datetime.utcnow()
    
    # åˆå§‹åŒ–ç»„ä»¶
    checker = LightweightHealthChecker(
        tcp_timeout=5.0,
        http_timeout=8.0,
        max_retries=2,
        max_concurrent=20
    )
    updater = SupabaseHealthUpdater()
    
    # è·å–å¾…æ£€æµ‹èŠ‚ç‚¹
    nodes = await updater.get_nodes_for_check(limit=batch_size)
    
    if not nodes:
        logger.warning("æ²¡æœ‰éœ€è¦æ£€æµ‹çš„èŠ‚ç‚¹")
        return {
            "status": "no_nodes",
            "checked_count": 0,
            "online_count": 0,
            "offline_count": 0,
            "suspect_count": 0,
            "duration_seconds": 0
        }
    
    logger.info(f"ğŸ“‹ è·å–åˆ° {len(nodes)} ä¸ªèŠ‚ç‚¹å¾…æ£€æµ‹")
    
    # æ‰§è¡Œæ£€æµ‹
    results = await checker.check_nodes_batch(nodes)
    
    # ç»Ÿè®¡ç»“æœ
    online_count = sum(1 for r in results if r.status == NodeStatus.ONLINE)
    offline_count = sum(1 for r in results if r.status == NodeStatus.OFFLINE)
    suspect_count = sum(1 for r in results if r.status == NodeStatus.SUSPECT)
    
    logger.info(f"ğŸ“Š æ£€æµ‹ç»“æœ: åœ¨çº¿={online_count}, ç¦»çº¿={offline_count}, å¯ç–‘={suspect_count}")
    
    # æ›´æ–°æ•°æ®åº“
    success, fail = await updater.update_node_status(results)
    logger.info(f"ğŸ’¾ æ•°æ®åº“æ›´æ–°: æˆåŠŸ={success}, å¤±è´¥={fail}")
    
    duration = (datetime.utcnow() - start_time).total_seconds()
    
    return {
        "status": "completed",
        "checked_count": len(results),
        "online_count": online_count,
        "offline_count": offline_count,
        "suspect_count": suspect_count,
        "update_success": success,
        "update_fail": fail,
        "duration_seconds": round(duration, 2),
        "checked_at": start_time.isoformat()
    }


# ç”¨äºæµ‹è¯•
if __name__ == "__main__":
    async def test():
        # æµ‹è¯•å•ä¸ªèŠ‚ç‚¹
        checker = LightweightHealthChecker()
        
        test_node = {
            "id": "test-1",
            "host": "1.1.1.1",
            "port": 443,
            "protocol": "vmess"
        }
        
        result = await checker.check_node(test_node)
        print(f"æ£€æµ‹ç»“æœ: {result}")
    
    asyncio.run(test())
