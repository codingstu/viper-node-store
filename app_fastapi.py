#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
=== viper-node-store FastAPIä¸»åº”ç”¨ï¼ˆSupabaseç‰ˆæœ¬ï¼‰ ===

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. ä» Supabase æ•°æ®åº“è¯»å–èŠ‚ç‚¹æ•°æ®
2. æä¾›èŠ‚ç‚¹æŸ¥è¯¢å’Œè¿‡æ»¤ API
3. æä¾›åŒæ­¥ä¿¡æ¯æŸ¥è¯¢
4. æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰ç²¾ç¡®æµ‹é€Ÿ

æ•°æ®æ¥æºï¼š
- æ‰€æœ‰èŠ‚ç‚¹æ•°æ®å­˜å‚¨åœ¨ Supabase public.nodes è¡¨
- SpiderFlow è´Ÿè´£æµ‹é€Ÿï¼Œç»“æœç›´æ¥å†™å…¥ Supabase
- viper-node-store ä»…è¯»å–å’Œå±•ç¤ºæ•°æ®

é›†æˆçš„æŠ€æœ¯æ ˆï¼š
- FastAPI: Webæ¡†æ¶
- Pydantic: æ•°æ®éªŒè¯
- Supabase: æ•°æ®åº“
- aiohttp: å¼‚æ­¥HTTPè¯·æ±‚
"""

from fastapi import FastAPI, Query, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import logging
import os
from datetime import datetime
import json
import aiohttp
import asyncio
from typing import List, Dict, Optional
import time
from apscheduler.schedulers.asyncio import AsyncIOScheduler

# ==================== é…ç½® ====================

# Supabase é…ç½®
SUPABASE_URL = os.environ.get("SUPABASE_URL", "https://hnlkwtkxbqiakeyienok.supabase.co")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImhubGt3dGt4YnFpYWtleWllbm9rIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjY5MDQwNTksImV4cCI6MjA4MjQ4MDA1OX0.Xg9vQdUfBdUW-IJaomEIRGsX6tB_k2grhrF4dm_aNME")

# SpiderFlow åç«¯ URLï¼ˆç”¨äºåŒæ­¥çŠ¶æ€æŸ¥è¯¢ï¼Œä¸ç”¨äºè·å–èŠ‚ç‚¹ï¼‰
SPIDERFLOW_API_URL = os.environ.get("SPIDERFLOW_API_URL", "http://localhost:8001")

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# ==================== Pydantic Models ====================

class PrecisionTestRequest(BaseModel):
    """ç²¾ç¡®æµ‹é€Ÿè¯·æ±‚æ¨¡å‹"""
    proxy_url: str
    test_file_size: int = 50

class LatencyTestRequest(BaseModel):
    """å»¶è¿Ÿæµ‹é€Ÿè¯·æ±‚æ¨¡å‹"""
    proxy_url: str

# ==================== FastAPI åº”ç”¨ ====================

app = FastAPI(
    title="viper-node-store API",
    description="èŠ‚ç‚¹æ•°æ®ç®¡ç†å’Œå±•ç¤ºå¹³å°ï¼ˆæ•°æ®æ¥æº: Supabaseï¼‰",
    version="2.0.0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==================== Supabase è¾…åŠ©å‡½æ•° ====================

async def get_supabase_nodes(
    limit: int = 500,
    show_free: bool = True,
    show_china: bool = True
) -> List[Dict]:
    """
    ä» Supabase è·å–èŠ‚ç‚¹æ•°æ®
    
    Args:
        limit: è¿”å›çš„æœ€å¤§èŠ‚ç‚¹æ•°
        show_free: æ˜¯å¦æ˜¾ç¤ºå…è´¹èŠ‚ç‚¹
        show_china: æ˜¯å¦æ˜¾ç¤ºä¸­å›½èŠ‚ç‚¹
    
    Returns:
        èŠ‚ç‚¹åˆ—è¡¨
    """
    try:
        # æ„é€  Supabase REST API æŸ¥è¯¢ URL
        url = f"{SUPABASE_URL}/rest/v1/nodes?select=*&limit={limit}"
        
        # æ·»åŠ è¿‡æ»¤æ¡ä»¶
        if not show_free:
            url += "&is_free=eq.false"
        
        headers = {
            "apikey": SUPABASE_KEY,
            "Authorization": f"Bearer {SUPABASE_KEY}",
            "Content-Type": "application/json"
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, headers=headers, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                if resp.status == 200:
                    raw_nodes = await resp.json()
                    
                    # è§£æèŠ‚ç‚¹æ•°æ®
                    nodes = []
                    for row in raw_nodes:
                        try:
                            # content å­—æ®µæ˜¯ JSONBï¼ŒåŒ…å«å®Œæ•´çš„èŠ‚ç‚¹ä¿¡æ¯
                            node_content = row.get("content", {})
                            if isinstance(node_content, str):
                                node_content = json.loads(node_content)
                            
                            # ç»„è£…èŠ‚ç‚¹å¯¹è±¡
                            node = {
                                "id": row.get("id", ""),
                                "protocol": node_content.get("protocol", ""),
                                "host": node_content.get("host", ""),
                                "port": node_content.get("port", 0),
                                "name": node_content.get("name", f"{node_content.get('host')}:{node_content.get('port')}"),
                                "country": node_content.get("country", "UNK"),
                                "link": node_content.get("link", ""),
                                "is_free": row.get("is_free", False),
                                "speed": row.get("speed", 0),
                                "latency": row.get("latency", 9999),
                                "updated_at": row.get("updated_at"),
                                "mainland_score": row.get("mainland_score", 0),
                                "mainland_latency": row.get("mainland_latency", 9999),
                                "overseas_score": row.get("overseas_score", 0),
                                "overseas_latency": row.get("overseas_latency", 9999),
                                # è®¡ç®—æ´»è·ƒçŠ¶æ€ï¼šlatency < 9999 è¡¨ç¤ºå·²æµ‹è¯•
                                "alive": row.get("latency", 9999) < 9999
                            }
                            nodes.append(node)
                        except Exception as e:
                            logger.warning(f"è§£æèŠ‚ç‚¹æ•°æ®å¤±è´¥: {e}")
                            continue
                    
                    logger.info(f"âœ… ä» Supabase è·å– {len(nodes)} ä¸ªèŠ‚ç‚¹")
                    return nodes
                else:
                    logger.error(f"âŒ Supabase è¿”å›é”™è¯¯: {resp.status}")
                    return []
    except Exception as e:
        logger.error(f"âŒ è·å– Supabase èŠ‚ç‚¹å¤±è´¥: {e}")
        return []

async def get_latest_sync_time() -> Optional[str]:
    """
    ä» Supabase è·å–æœ€åä¸€æ¬¡æ›´æ–°æ—¶é—´ï¼ˆæ‰€æœ‰èŠ‚ç‚¹ä¸­çš„æœ€æ–° updated_atï¼‰
    """
    try:
        url = f"{SUPABASE_URL}/rest/v1/nodes?select=updated_at&order=updated_at.desc&limit=1"
        
        headers = {
            "apikey": SUPABASE_KEY,
            "Authorization": f"Bearer {SUPABASE_KEY}",
            "Content-Type": "application/json"
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.get(url, headers=headers, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    if data and len(data) > 0:
                        return data[0].get("updated_at")
        return None
    except Exception as e:
        logger.warning(f"âš ï¸  è·å–æœ€åæ›´æ–°æ—¶é—´å¤±è´¥: {e}")
        return None

# ==================== å¯åŠ¨å’Œå…³é—­ ====================

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler = None

async def periodic_pull_from_supabase():
    """
    å®šæ—¶æ‹‰å–ä»»åŠ¡ï¼šæ¯12åˆ†é’Ÿä» Supabase æ‹‰å–ä¸€æ¬¡æœ€æ–°çš„èŠ‚ç‚¹æ•°æ®
    è¿™å¯ä»¥ç¡®ä¿ viper-node-store çš„å†…å­˜ç¼“å­˜ä¿æŒæœ€æ–°
    """
    try:
        logger.info("ğŸ“¥ å¼€å§‹å®šæ—¶æ‹‰å– Supabase èŠ‚ç‚¹æ•°æ®...")
        nodes = await get_supabase_nodes(limit=10000)
        logger.info(f"âœ… å®šæ—¶æ‹‰å–å®Œæˆï¼šè·å– {len(nodes)} ä¸ªèŠ‚ç‚¹")
    except Exception as e:
        logger.warning(f"âš ï¸  å®šæ—¶æ‹‰å–å¤±è´¥: {e}")

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    global scheduler
    
    logger.info("=" * 60)
    logger.info("ğŸš€ viper-node-store æ­£åœ¨å¯åŠ¨...")
    logger.info("ğŸ“Š æ•°æ®æ¥æº: Supabase public.nodes è¡¨")
    logger.info("=" * 60)
    
    # éªŒè¯ Supabase è¿æ¥
    try:
        nodes = await get_supabase_nodes(limit=1)
        logger.info("âœ… Supabase è¿æ¥æˆåŠŸ")
    except Exception as e:
        logger.warning(f"âš ï¸  Supabase è¿æ¥å¤±è´¥: {e}")
    
    # å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
    try:
        scheduler = AsyncIOScheduler()
        
        # æ·»åŠ å®šæ—¶ä»»åŠ¡ï¼šæ¯12åˆ†é’Ÿæ‹‰å–ä¸€æ¬¡ Supabase æ•°æ®
        scheduler.add_job(
            periodic_pull_from_supabase,
            'interval',
            minutes=12,
            id='supabase_pull',
            name='Supabase å®šæ—¶æ‹‰å–'
        )
        
        scheduler.start()
        logger.info("âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨ï¼ˆæ¯12åˆ†é’Ÿæ‹‰å–ä¸€æ¬¡ Supabase æ•°æ®ï¼‰")
    except Exception as e:
        logger.warning(f"âš ï¸  å¯åŠ¨å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å¤±è´¥: {e}")

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶çš„æ¸…ç†"""
    global scheduler
    
    logger.info("ğŸ›‘ viper-node-store æ­£åœ¨å…³é—­...")
    
    # å…³é—­è°ƒåº¦å™¨
    if scheduler and scheduler.running:
        scheduler.shutdown()
        logger.info("âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å…³é—­")

# ==================== å¥åº·æ£€æŸ¥ ====================

@app.get("/")
async def root():
    """æ ¹è·¯ç”± - è¿”å› HTML å‰ç«¯"""
    return {"message": "viper-node-store API", "status": "running", "data_source": "Supabase"}

@app.get("/api/status")
async def status():
    """API çŠ¶æ€æ£€æŸ¥"""
    return {
        "status": "running",
        "version": "2.0.0",
        "data_source": "Supabase",
        "timestamp": datetime.now().isoformat()
    }

# ==================== èŠ‚ç‚¹ API ====================

@app.get("/api/nodes")
async def get_nodes(
    limit: int = Query(50, ge=1, le=500),
    show_free: bool = Query(True),
    show_china: bool = Query(True)
):
    """
    è·å–èŠ‚ç‚¹åˆ—è¡¨ï¼ˆä» Supabaseï¼‰
    
    Parameters:
    - limit: è¿”å›èŠ‚ç‚¹æ•°é‡é™åˆ¶ï¼ˆ1-500ï¼‰
    - show_free: æ˜¯å¦æ˜¾ç¤ºå…è´¹èŠ‚ç‚¹
    - show_china: æ˜¯å¦æ˜¾ç¤ºä¸­å›½èŠ‚ç‚¹
    """
    try:
        nodes = await get_supabase_nodes(limit=limit, show_free=show_free, show_china=show_china)
        return nodes
    except Exception as e:
        logger.error(f"âŒ è·å–èŠ‚ç‚¹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== åŒæ­¥ä¿¡æ¯ API ====================

@app.get("/api/sync-info")
async def get_sync_info():
    """
    è·å–åŒæ­¥ä¿¡æ¯ï¼ˆç”¨äºå‰ç«¯æ˜¾ç¤º"ä¸Šæ¬¡æ›´æ–°äºXåˆ†é’Ÿå‰"ï¼‰
    
    è¿”å›ï¼š
    - last_updated_at: ISOæ ¼å¼æ—¶é—´æˆ³
    - minutes_ago: è·ç¦»ç°åœ¨çš„åˆ†é’Ÿæ•°
    - nodes_count: èŠ‚ç‚¹æ€»æ•°
    - active_count: æ´»è·ƒèŠ‚ç‚¹æ•°ï¼ˆå·²æµ‹è¯•ï¼‰
    - source: æ•°æ®æ¥æºï¼ˆsupabaseï¼‰
    """
    try:
        # è·å–æ‰€æœ‰èŠ‚ç‚¹ç»Ÿè®¡
        nodes = await get_supabase_nodes(limit=10000)
        
        # è·å–æœ€åæ›´æ–°æ—¶é—´
        last_updated_at = await get_latest_sync_time()
        
        # è®¡ç®—åˆ†é’Ÿå·®å¼‚
        minutes_ago = 0
        if last_updated_at:
            try:
                last_synced = datetime.fromisoformat(last_updated_at.replace('Z', '+00:00'))
                now = datetime.now(last_synced.tzinfo) if last_synced.tzinfo else datetime.now()
                minutes_ago = max(0, int((now - last_synced).total_seconds() / 60))
            except Exception as e:
                logger.debug(f"è®¡ç®—æ—¶é—´å·®å¼‚å¤±è´¥: {e}")
                minutes_ago = 0
        
        # ç»Ÿè®¡èŠ‚ç‚¹
        active_count = len([n for n in nodes if n.get("alive")])
        
        return {
            "last_updated_at": last_updated_at or datetime.now().isoformat(),
            "minutes_ago": minutes_ago,
            "nodes_count": len(nodes),
            "active_count": active_count,
            "source": "supabase",
            "sync_metadata": {
                "total_nodes": len(nodes),
                "tested_nodes": active_count,
                "pending_test": len(nodes) - active_count
            }
        }
    except Exception as e:
        logger.error(f"âŒ è·å–åŒæ­¥ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
        return {
            "last_updated_at": datetime.now().isoformat(),
            "minutes_ago": 0,
            "nodes_count": 0,
            "active_count": 0,
            "source": "error",
            "error": str(e)
        }

# ==================== æ‰‹åŠ¨è§¦å‘è½®è¯¢ ====================

@app.post("/api/sync/poll-now")
async def trigger_manual_poll(background_tasks = None):
    """
    æ‰‹åŠ¨è§¦å‘è½®è¯¢ï¼ˆå‘ SpiderFlow å‘é€è¯·æ±‚ï¼‰
    æ³¨ï¼šå®é™…æ•°æ®ä»ä» Supabase è¯»å–
    """
    try:
        # å‘ SpiderFlow è§¦å‘è½®è¯¢
        async with aiohttp.ClientSession() as session:
            trigger_url = f"{SPIDERFLOW_API_URL}/api/sync/poll-now"
            try:
                async with session.post(trigger_url, timeout=aiohttp.ClientTimeout(total=5)) as resp:
                    if resp.status == 200:
                        logger.info("âœ… å·²å‘ SpiderFlow å‘é€è½®è¯¢è¯·æ±‚")
                    else:
                        logger.warning(f"âš ï¸  SpiderFlow è½®è¯¢è¿”å› {resp.status}")
            except Exception as e:
                logger.warning(f"âš ï¸  æ— æ³•è¿æ¥ SpiderFlow: {e}")
        
        return {
            "status": "poll_triggered",
            "message": "å·²è¯·æ±‚ SpiderFlow æ‰§è¡Œè½®è¯¢ï¼Œç»“æœå°†ä¿å­˜åˆ° Supabase",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"âŒ è§¦å‘è½®è¯¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== ç²¾ç¡®æµ‹é€Ÿ API ====================

@app.post("/api/nodes/precision-test")
async def precision_speed_test(request: PrecisionTestRequest):
    """
    ç”¨æˆ·å‘èµ·çš„ç²¾ç¡®æµ‹é€Ÿ - çœŸå®ä¸‹è½½æµ‹è¯•
    """
    try:
        proxy_url = request.proxy_url
        test_file_size = request.test_file_size
        
        logger.info(f"âš¡ ç”¨æˆ·å‘èµ·ç²¾ç¡®æµ‹é€Ÿ | æ–‡ä»¶å¤§å°: {test_file_size}MB")
        
        # ç”Ÿæˆæµ‹è¯•æ–‡ä»¶URL
        test_file_url = f"https://speed.cloudflare.com/__down?bytes={test_file_size * 1024 * 1024}"
        
        start_time = time.time()
        bytes_downloaded = 0
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(test_file_url, timeout=aiohttp.ClientTimeout(total=60)) as resp:
                    if resp.status == 200:
                        async for chunk in resp.content.iter_chunked(8192):
                            bytes_downloaded += len(chunk)
            
            download_time = time.time() - start_time
            
            if download_time <= 0:
                download_time = 0.001
            
            # è®¡ç®—é€Ÿåº¦ (MB/s)
            speed_mbps = (bytes_downloaded / (1024 * 1024)) / download_time
            
            logger.info(f"âœ… ç²¾ç¡®æµ‹é€Ÿå®Œæˆ | å¤§å°: {bytes_downloaded/(1024*1024):.1f}MB | æ—¶é—´: {download_time:.1f}s | é€Ÿåº¦: {speed_mbps:.1f}MB/s")
            
            return {
                "status": "success",
                "speed_mbps": round(speed_mbps, 2),
                "download_time_seconds": round(download_time, 2),
                "traffic_consumed_mb": round(bytes_downloaded / (1024 * 1024), 2),
                "bytes_downloaded": bytes_downloaded,
                "test_file_size_requested_mb": test_file_size,
                "message": f"ç²¾ç¡®æµ‹é€Ÿå®Œæˆ: {speed_mbps:.1f} MB/s",
                "timestamp": datetime.now().isoformat()
            }
        except asyncio.TimeoutError:
            logger.error(f"ç²¾ç¡®æµ‹é€Ÿè¶…æ—¶ (> 60ç§’)")
            return {
                "status": "timeout",
                "speed_mbps": 0,
                "message": "æµ‹é€Ÿè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•",
                "timestamp": datetime.now().isoformat()
            }
        except Exception as inner_err:
            logger.error(f"ç²¾ç¡®æµ‹é€Ÿä¸‹è½½å¤±è´¥: {inner_err}")
            if bytes_downloaded > 0:
                download_time = time.time() - start_time
                speed_mbps = (bytes_downloaded / (1024 * 1024)) / download_time
                return {
                    "status": "partial_success",
                    "speed_mbps": round(speed_mbps, 2),
                    "download_time_seconds": round(download_time, 2),
                    "traffic_consumed_mb": round(bytes_downloaded / (1024 * 1024), 2),
                    "message": f"éƒ¨åˆ†æµ‹è¯•: {speed_mbps:.1f} MB/s",
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "status": "error",
                    "speed_mbps": 0,
                    "message": f"æµ‹é€Ÿå¤±è´¥: {str(inner_err)[:50]}",
                    "timestamp": datetime.now().isoformat()
                }
    except Exception as e:
        logger.error(f"ç²¾ç¡®æµ‹é€Ÿå¼‚å¸¸: {e}")
        return {
            "status": "error",
            "speed_mbps": 0,
            "message": f"API é”™è¯¯: {str(e)[:50]}",
            "timestamp": datetime.now().isoformat()
        }

@app.post("/api/nodes/latency-test")
async def latency_test(request: LatencyTestRequest):
    """
    å»¶è¿Ÿæµ‹è¯• - ç®€å•çš„ ping å»¶è¿Ÿæµ‹è¯•
    """
    try:
        proxy_url = request.proxy_url
        
        logger.info(f"âš¡ æ‰§è¡Œå»¶è¿Ÿæµ‹è¯•")
        
        start_time = time.time()
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.head(proxy_url, timeout=aiohttp.ClientTimeout(total=10), allow_redirects=False) as resp:
                    latency = int((time.time() - start_time) * 1000)  # æ¯«ç§’
                    
                    return {
                        "status": "success",
                        "latency": latency,
                        "latency_ms": latency,
                        "timestamp": datetime.now().isoformat()
                    }
        except asyncio.TimeoutError:
            return {
                "status": "timeout",
                "latency": 9999,
                "message": "å»¶è¿Ÿæµ‹è¯•è¶…æ—¶",
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            logger.warning(f"å»¶è¿Ÿæµ‹è¯•å¤±è´¥: {e}")
            return {
                "status": "error",
                "latency": 9999,
                "message": str(e),
                "timestamp": datetime.now().isoformat()
            }
    except Exception as e:
        logger.error(f"å»¶è¿Ÿæµ‹è¯•å¼‚å¸¸: {e}")
        return {
            "status": "error",
            "latency": 9999,
            "message": f"API é”™è¯¯: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }

# ==================== ä¸»ç¨‹åº ====================

if __name__ == "__main__":
    import uvicorn
    
    logger.info("=" * 60)
    logger.info("å¯åŠ¨ viper-node-store API æœåŠ¡ (Supabase ç‰ˆæœ¬)")
    logger.info("=" * 60)
    
    uvicorn.run(
        "app_fastapi:app",
        host="0.0.0.0",
        port=8002,
        reload=False,
        log_level="info"
    )
