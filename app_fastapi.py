#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
=== viper-node-store FastAPIä¸»åº”ç”¨ ===

æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ¥æ”¶SpiderFlowçš„Webhookæ¨é€ï¼ˆå®æ—¶æ•°æ®æ›´æ–°ï¼‰
2. å®šæ—¶è½®è¯¢SpiderFlow APIï¼ˆå¤‡ç”¨åŒæ­¥æœºåˆ¶ï¼‰
3. æä¾›èŠ‚ç‚¹æ•°æ®å¯¼å‡ºAPI
4. ç®¡ç†æœ¬åœ°èŠ‚ç‚¹æ•°æ®åº“
5. æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰ç²¾ç¡®æµ‹é€Ÿ

é›†æˆçš„æŠ€æœ¯æ ˆï¼š
- FastAPI: Webæ¡†æ¶
- APScheduler: å®šæ—¶ä»»åŠ¡è°ƒåº¦
- Pydantic: æ•°æ®éªŒè¯
- aiohttp: å¼‚æ­¥HTTPè¯·æ±‚
"""

from fastapi import FastAPI, BackgroundTasks, Query, HTTPException
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import logging
import asyncio
import os
from datetime import datetime
from pathlib import Path
import json

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from webhook_receiver import webhook_router, verify_webhook_signature, load_nodes_from_file
from data_sync import (
    DataSyncScheduler, 
    poll_spiderflow_nodes, 
    get_exported_nodes,
    get_sync_statistics,
    POLL_INTERVAL,
    load_local_nodes
)

# ==================== é…ç½® ====================

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# ==================== Pydantic Models ====================

class PrecisionTestRequest(BaseModel):
    """ç²¾ç¡®æµ‹é€Ÿè¯·æ±‚æ¨¡å‹"""
    proxy_url: str
    test_file_size: int = 50

class LatencyTestRequest(BaseModel):
    """å»¶è¿Ÿæµ‹é€Ÿè¯·æ±‚æ¨¡å‹"""
    proxy_url: str

# FastAPIåº”ç”¨
app = FastAPI(
    title="viper-node-store API",
    description="èŠ‚ç‚¹æ•°æ®ç®¡ç†å’ŒåŒæ­¥å¹³å°",
    version="1.0.0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€è°ƒåº¦å™¨
sync_scheduler: DataSyncScheduler = None

# ==================== å¯åŠ¨å’Œå…³é—­ ====================

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶çš„åˆå§‹åŒ–"""
    global sync_scheduler
    
    logger.info("=" * 60)
    logger.info("ğŸš€ viper-node-store æ­£åœ¨å¯åŠ¨...")
    logger.info("=" * 60)
    
    # åˆå§‹åŒ–å®šæ—¶è½®è¯¢è°ƒåº¦å™¨
    sync_scheduler = DataSyncScheduler()
    asyncio.create_task(sync_scheduler.start())
    
    # æ‰§è¡Œé¦–æ¬¡è½®è¯¢
    logger.info("ğŸ“¥ æ‰§è¡Œé¦–æ¬¡èŠ‚ç‚¹è½®è¯¢...")
    await poll_spiderflow_nodes()
    
    logger.info("âœ… viper-node-store å¯åŠ¨å®Œæˆ")

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶çš„æ¸…ç†"""
    global sync_scheduler
    
    logger.info("ğŸ›‘ viper-node-store æ­£åœ¨å…³é—­...")
    if sync_scheduler:
        await sync_scheduler.stop()
    logger.info("âœ… viper-node-store å·²å…³é—­")

# ==================== æ ¹è·¯ç”± ====================

@app.get("/")
async def root():
    """APIæ–‡æ¡£å’ŒåŸºæœ¬ä¿¡æ¯"""
    return {
        "name": "viper-node-store",
        "version": "1.0.0",
        "description": "å®æ—¶èŠ‚ç‚¹æ•°æ®åŒæ­¥å’Œç®¡ç†å¹³å°",
        "features": [
            "Webhookå®æ—¶æ¨é€",
            "å®šæ—¶è½®è¯¢å¤‡ç”¨",
            "èŠ‚ç‚¹æ•°æ®å¯¼å‡º",
            "ç»Ÿè®¡ä¿¡æ¯æŸ¥è¯¢",
            "ç”¨æˆ·ç²¾ç¡®æµ‹é€Ÿ"
        ],
        "endpoints": {
            "docs": "/docs",
            "redoc": "/redoc",
            "openapi": "/openapi.json",
            "nodes": "/api/nodes",
            "webhook": "/webhook/nodes-update",
            "status": "/api/status"
        }
    }

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "scheduler_running": sync_scheduler.running if sync_scheduler else False
    }

# ==================== èŠ‚ç‚¹æ•°æ®API ==================== 

@app.get("/api/nodes")
async def get_nodes(
    country: str = Query(None, description="æŒ‰å›½å®¶ä»£ç ç­›é€‰"),
    protocol: str = Query(None, description="æŒ‰åè®®ç­›é€‰"),
    min_speed: float = Query(None, description="æœ€å°é€Ÿåº¦(MB/s)"),
    max_latency: int = Query(None, description="æœ€å¤§å»¶è¿Ÿ(ms)"),
    format: str = Query("json", description="è¾“å‡ºæ ¼å¼: json, clash, subscription")
):
    """
    è·å–èŠ‚ç‚¹åˆ—è¡¨
    
    ç¤ºä¾‹ï¼š
    - /api/nodes â†’ æ‰€æœ‰èŠ‚ç‚¹
    - /api/nodes?country=SG â†’ æ–°åŠ å¡èŠ‚ç‚¹
    - /api/nodes?min_speed=50 â†’ é€Ÿåº¦â‰¥50MB/sçš„èŠ‚ç‚¹
    - /api/nodes?format=clash â†’ Clashé…ç½®æ ¼å¼
    """
    try:
        data = load_nodes_from_file()
        nodes = data.get("nodes", [])
        
        # åº”ç”¨è¿‡æ»¤æ¡ä»¶
        if country:
            nodes = [n for n in nodes if n.get("country") == country.upper()]
        
        if protocol:
            nodes = [n for n in nodes if n.get("protocol") == protocol.lower()]
        
        if min_speed:
            nodes = [n for n in nodes if n.get("speed", 0) >= min_speed]
        
        if max_latency:
            nodes = [n for n in nodes if n.get("latency", 999999) <= max_latency]
        
        # æŒ‰æ ¼å¼è¿”å›
        if format == "json":
            return {
                "total": len(nodes),
                "nodes": nodes,
                "last_updated": data.get("last_updated"),
                "filtered": bool(country or protocol or min_speed or max_latency)
            }
        
        elif format == "clash":
            # TODO: å®ç°Clashæ ¼å¼
            return {"format": "clash", "status": "not_implemented"}
        
        elif format == "subscription":
            # TODO: å®ç°è®¢é˜…æ ¼å¼
            return {"format": "subscription", "status": "not_implemented"}
        
        return {"error": "ä¸æ”¯æŒçš„æ ¼å¼"}
        
    except Exception as e:
        logger.error(f"è·å–èŠ‚ç‚¹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/nodes/export")
async def export_nodes_data(
    format: str = Query("json", description="å¯¼å‡ºæ ¼å¼"),
    include_metadata: bool = Query(True, description="æ˜¯å¦åŒ…å«å…ƒæ•°æ®")
):
    """
    å¯¼å‡ºèŠ‚ç‚¹æ•°æ®æ–‡ä»¶
    
    æ”¯æŒçš„æ ¼å¼ï¼š
    - json: JSONæ ¼å¼ï¼ˆé»˜è®¤ï¼‰
    - clash: Clashé…ç½®æ–‡ä»¶
    - subscription: è®¢é˜…é“¾æ¥
    """
    try:
        if format == "json":
            content = get_exported_nodes(format="json")
            return JSONResponse(
                content=json.loads(content),
                media_type="application/json"
            )
        
        return {"error": "ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼"}
        
    except Exception as e:
        logger.error(f"å¯¼å‡ºèŠ‚ç‚¹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== åŒæ­¥çŠ¶æ€API ====================

@app.get("/api/sync/status")
async def get_sync_status():
    """
    è·å–æ•°æ®åŒæ­¥çŠ¶æ€
    
    è¿”å›ï¼š
    - æ€»èŠ‚ç‚¹æ•°
    - æœ€ååŒæ­¥æ—¶é—´
    - åŒæ­¥æ–¹æ³•ï¼ˆWebhook/è½®è¯¢ï¼‰
    - Webhook/è½®è¯¢ç»Ÿè®¡ä¿¡æ¯
    - è½®è¯¢é—´éš”
    """
    try:
        stats = get_sync_statistics()
        return {
            **stats,
            "poll_interval_seconds": POLL_INTERVAL,
            "scheduler_status": "running" if sync_scheduler and sync_scheduler.running else "stopped"
        }
    except Exception as e:
        logger.error(f"è·å–åŒæ­¥çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/sync-info")
async def get_sync_info():
    """
    è·å–åŒæ­¥ä¿¡æ¯ï¼ˆç”¨äºå‰ç«¯æ˜¾ç¤º"ä¸Šæ¬¡æ›´æ–°äºXåˆ†é’Ÿå‰"ï¼‰
    
    è¿”å›ï¼š
    - last_updated_at: ISOæ ¼å¼æ—¶é—´æˆ³
    - minutes_ago: è·ç¦»ç°åœ¨çš„åˆ†é’Ÿæ•°
    - nodes_count: èŠ‚ç‚¹æ€»æ•°
    - active_count: æ´»è·ƒèŠ‚ç‚¹æ•°ï¼ˆnot is_staleï¼‰
    - source: æ•°æ®æ¥æºï¼ˆwebhook/poll/localï¼‰
    - needs_verification: å¾…éªŒè¯èŠ‚ç‚¹æ•°
    """
    try:
        data = load_local_nodes()
        nodes = data.get("nodes", [])
        sync_metadata = data.get("sync_metadata", {})
        last_synced_at_str = data.get("last_synced_at")
        source = data.get("last_synced_from", "local")
        
        logger.debug(f"è·å–åŒæ­¥ä¿¡æ¯: nodes={len(nodes)}, last_synced={last_synced_at_str}, source={source}")
        
        # è®¡ç®—åˆ†é’Ÿå·®å¼‚
        minutes_ago = 0
        if last_synced_at_str:
            try:
                last_synced = datetime.fromisoformat(last_synced_at_str.replace('Z', '+00:00'))
                now = datetime.now(last_synced.tzinfo) if last_synced.tzinfo else datetime.now()
                minutes_ago = max(0, int((now - last_synced).total_seconds() / 60))
            except Exception as e:
                logger.debug(f"è®¡ç®—æ—¶é—´å·®å¼‚å¤±è´¥: {e}")
                minutes_ago = 0
        else:
            # å¦‚æœæ²¡æœ‰last_synced_atï¼Œè¯´æ˜è¿˜æ²¡æœ‰åŒæ­¥è¿‡æ•°æ®
            logger.debug("å°šæœªè¿›è¡Œæ•°æ®åŒæ­¥")
        
        # ç»Ÿè®¡èŠ‚ç‚¹æ•°é‡
        active_count = len([n for n in nodes if not n.get("is_stale")])
        needs_verification_count = len([n for n in nodes if n.get("needs_verification")])
        
        response = {
            "last_updated_at": last_synced_at_str or datetime.now().isoformat(),
            "minutes_ago": minutes_ago,
            "nodes_count": len(nodes),
            "active_count": active_count,
            "source": source,
            "needs_verification": needs_verification_count,
            "sync_metadata": sync_metadata
        }
        
        logger.debug(f"âœ… è¿”å›åŒæ­¥ä¿¡æ¯: {response}")
        return response
    except Exception as e:
        logger.error(f"âŒ è·å–åŒæ­¥ä¿¡æ¯å¤±è´¥: {e}", exc_info=True)
        return {
            "last_updated_at": datetime.now().isoformat(),
            "minutes_ago": 0,
            "nodes_count": 0,
            "active_count": 0,
            "source": "error",
            "needs_verification": 0,
            "error": str(e)
        }
            "needs_verification": 0,
            "error": str(e)
        }


@app.post("/api/sync/poll-now")
async def trigger_manual_poll(background_tasks: BackgroundTasks):
    """
    ç«‹å³æ‰§è¡Œä¸€æ¬¡è½®è¯¢ï¼ˆç”¨äºæµ‹è¯•æˆ–ç´§æ€¥æ›´æ–°ï¼‰
    """
    try:
        background_tasks.add_task(poll_spiderflow_nodes)
        return {
            "status": "poll_triggered",
            "message": "å·²è§¦å‘æ‰‹åŠ¨è½®è¯¢ï¼Œåœ¨åå°æ‰§è¡Œ",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"æ‰‹åŠ¨è½®è¯¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== Webhookè·¯ç”±é›†æˆ ====================

app.include_router(webhook_router)

# ==================== ç»Ÿè®¡å’Œåˆ†æAPI ====================

@app.get("/api/stats/summary")
async def get_summary_stats():
    """è·å–æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯"""
    try:
        data = load_nodes_from_file()
        nodes = data.get("nodes", [])
        
        # å›½å®¶åˆ†å¸ƒ
        country_dist = {}
        for node in nodes:
            country = node.get("country", "UNKNOWN")
            country_dist[country] = country_dist.get(country, 0) + 1
        
        # åè®®åˆ†å¸ƒ
        protocol_dist = {}
        for node in nodes:
            protocol = node.get("protocol", "unknown")
            protocol_dist[protocol] = protocol_dist.get(protocol, 0) + 1
        
        # å¹³å‡æŒ‡æ ‡
        avg_latency = sum(n.get("latency", 0) for n in nodes) / len(nodes) if nodes else 0
        avg_speed = sum(n.get("speed", 0) for n in nodes) / len(nodes) if nodes else 0
        
        return {
            "total_nodes": len(nodes),
            "country_distribution": country_dist,
            "protocol_distribution": protocol_dist,
            "average_latency_ms": round(avg_latency, 2),
            "average_speed_mbps": round(avg_speed, 2),
            "last_updated": data.get("last_updated")
        }
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/stats/top-nodes")
async def get_top_nodes(
    metric: str = Query("speed", description="æ’åºæŒ‡æ ‡: speed, latency"),
    limit: int = Query(10, description="è¿”å›æ•°é‡"),
    country: str = Query(None, description="æŒ‰å›½å®¶ç­›é€‰")
):
    """
    è·å–æ’åé å‰çš„èŠ‚ç‚¹
    
    ç¤ºä¾‹ï¼š
    - /api/stats/top-nodes?metric=speed&limit=20 â†’ æœ€å¿«çš„20ä¸ªèŠ‚ç‚¹
    - /api/stats/top-nodes?metric=latency&limit=10 â†’ å»¶è¿Ÿæœ€ä½çš„10ä¸ªèŠ‚ç‚¹
    """
    try:
        data = load_nodes_from_file()
        nodes = data.get("nodes", [])
        
        if country:
            nodes = [n for n in nodes if n.get("country") == country.upper()]
        
        if metric == "speed":
            sorted_nodes = sorted(nodes, key=lambda x: x.get("speed", 0), reverse=True)
        elif metric == "latency":
            sorted_nodes = sorted(nodes, key=lambda x: x.get("latency", 999999))
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ’åºæŒ‡æ ‡: {metric}")
        
        return {
            "metric": metric,
            "country": country or "all",
            "total": len(nodes),
            "returned": len(sorted_nodes[:limit]),
            "nodes": sorted_nodes[:limit]
        }
    except Exception as e:
        logger.error(f"è·å–æ’åèŠ‚ç‚¹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ==================== æµ‹é€ŸAPI ====================

@app.post("/api/nodes/test-single")
async def test_single_node(
    proxy_url: str,
    background_tasks: BackgroundTasks,
    timeout: int = Query(10, description="è¶…æ—¶æ—¶é—´(ç§’)")
):
    """
    æµ‹è¯•å•ä¸ªèŠ‚ç‚¹
    
    æ”¯æŒä¸‰å±‚æµ‹è¯•æœºåˆ¶ï¼š
    1. å‰ç«¯HEADè¯·æ±‚ï¼ˆæœ€å¿«ï¼Œæœ€å°‘æµé‡ï¼‰
    2. åç«¯HEADè¯·æ±‚ï¼ˆå…¼å®¹æ€§å¥½ï¼‰
    3. CF Workerå®é™…ä¸‹è½½ï¼ˆç²¾ç¡®ä½†æ…¢ï¼‰
    """
    try:
        # TODO: å®ç°èŠ‚ç‚¹æµ‹è¯•é€»è¾‘
        return {
            "proxy_url": proxy_url,
            "status": "test_initiated",
            "message": "å·²å‘èµ·æµ‹è¯•ï¼Œè¯·ç¨å€™...",
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"èŠ‚ç‚¹æµ‹è¯•å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/nodes/latency-test")
async def latency_test(request: LatencyTestRequest):
    """
    å»¶è¿Ÿæµ‹é€Ÿ - æµ‹è¯•ä»£ç†è¿æ¥å»¶è¿Ÿ
    
    å·¥ä½œæµç¨‹ï¼š
    1. æ¥æ”¶ä»£ç†URL
    2. å‘èµ·HTTP HEADè¯·æ±‚æµ‹å»¶è¿Ÿ
    3. è¿”å›å¾€è¿”æ—¶é—´ï¼ˆRTTï¼‰
    
    è¯·æ±‚ç¤ºä¾‹:
    POST /api/nodes/latency-test
    {
      "proxy_url": "vmess://..."
    }
    
    è¿”å›: { status, latency, message }
    """
    import aiohttp
    import time
    
    proxy_url = request.proxy_url
    
    try:
        logger.info(f"âš¡ ç”¨æˆ·å‘èµ·å»¶è¿Ÿæµ‹é€Ÿ | ä»£ç†: {proxy_url[:50]}...")
        
        # ä½¿ç”¨Cloudflareæˆ–å…¶ä»–å¿«é€Ÿå“åº”çš„æœåŠ¡æµ‹å»¶è¿Ÿ
        test_url = "https://www.cloudflare.com"
        
        start_time = time.time()
        
        try:
            async with aiohttp.ClientSession() as session:
                async with session.head(test_url, timeout=aiohttp.ClientTimeout(total=10)) as resp:
                    latency = (time.time() - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
                    
                    if resp.status in [200, 301, 302, 404]:
                        logger.info(f"âœ… å»¶è¿Ÿæµ‹é€Ÿå®Œæˆ | å»¶è¿Ÿ: {latency:.0f}ms")
                        return {
                            "status": "success",
                            "latency": round(latency, 0),
                            "message": f"å»¶è¿Ÿ: {latency:.0f}ms",
                            "timestamp": datetime.now().isoformat()
                        }
                    else:
                        raise Exception(f"HTTP {resp.status}")
        
        except asyncio.TimeoutError:
            logger.error(f"å»¶è¿Ÿæµ‹é€Ÿè¶…æ—¶ (> 10ç§’)")
            return {
                "status": "timeout",
                "latency": 0,
                "message": "å»¶è¿Ÿæµ‹é€Ÿè¶…æ—¶",
                "timestamp": datetime.now().isoformat()
            }
        except Exception as inner_err:
            logger.error(f"å»¶è¿Ÿæµ‹é€Ÿå¤±è´¥: {inner_err}")
            return {
                "status": "error",
                "latency": 0,
                "message": f"æµ‹é€Ÿå¤±è´¥: {str(inner_err)[:50]}",
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"å»¶è¿Ÿæµ‹é€Ÿå¼‚å¸¸: {e}")
        return {
            "status": "error",
            "latency": 0,
            "message": f"API é”™è¯¯: {str(e)[:50]}",
            "timestamp": datetime.now().isoformat()
        }

@app.post("/api/nodes/precision-test")
async def precision_speed_test(
    request: PrecisionTestRequest,
    background_tasks: BackgroundTasks = None
):
    """
    ç”¨æˆ·å‘èµ·çš„ç²¾ç¡®æµ‹é€Ÿ - çœŸå®ä¸‹è½½æµ‹è¯•
    
    å·¥ä½œæµç¨‹ï¼š
    1. ç”¨æˆ·ç‚¹å‡»[ç²¾ç¡®æµ‹é€Ÿ]æŒ‰é’®
    2. åå°æ‰§è¡ŒçœŸå®ä¸‹è½½æµ‹é€Ÿ
    3. å³æ—¶è¿”å›åˆå§‹å“åº”
    4. ç”¨æˆ·ç•Œé¢è½®è¯¢è·å–ç»“æœ
    
    è¯·æ±‚ç¤ºä¾‹:
    POST /api/nodes/precision-test
    {
      "proxy_url": "vmess://...",
      "test_file_size": 50
    }
    
    è¿”å›: { status, speed_mbps, download_time_seconds, traffic_consumed_mb, ... }
    """
    import aiohttp
    import time
    
    proxy_url = request.proxy_url
    test_file_size = request.test_file_size
    
    try:
        logger.info(f"âš¡ ç”¨æˆ·å‘èµ·ç²¾ç¡®æµ‹é€Ÿ | æ–‡ä»¶å¤§å°: {test_file_size}MB")
        
        # ç”Ÿæˆä¸€ä¸ªæµ‹è¯•æ–‡ä»¶URL
        test_file_url = f"https://speed.cloudflare.com/__down?bytes={test_file_size * 1024 * 1024}"
        
        start_time = time.time()
        bytes_downloaded = 0
        download_time = 0
        
        try:
            # å¼‚æ­¥ä¸‹è½½æ–‡ä»¶ï¼Œä½¿ç”¨è¶…æ—¶æ§åˆ¶
            async with aiohttp.ClientSession() as session:
                async with session.get(test_file_url, timeout=aiohttp.ClientTimeout(total=60)) as resp:
                    if resp.status == 200:
                        async for chunk in resp.content.iter_chunked(8192):
                            bytes_downloaded += len(chunk)
                    else:
                        raise Exception(f"HTTP {resp.status}")
            
            download_time = time.time() - start_time
            
            if download_time <= 0:
                download_time = 0.001
            
            # è®¡ç®—é€Ÿåº¦ (MB/s)
            speed_mbps = (bytes_downloaded / (1024 * 1024)) / download_time
            
            logger.info(f"âœ… ç²¾ç¡®æµ‹é€Ÿå®Œæˆ | å¤§å°: {bytes_downloaded/(1024*1024):.1f}MB | æ—¶é—´: {download_time:.1f}s | é€Ÿåº¦: {speed_mbps:.1f}MB/s")
            
            return {
                "status": "success",
                "speed_mbps": round(speed_mbps, 2),
                "download_time_seconds": round(download_time, 2),
                "traffic_consumed_mb": round(bytes_downloaded / (1024 * 1024), 2),
                "bytes_downloaded": bytes_downloaded,
                "test_file_size_requested_mb": test_file_size,
                "message": f"ç²¾ç¡®æµ‹é€Ÿå®Œæˆ: {speed_mbps:.1f} MB/s",
                "timestamp": datetime.now().isoformat()
            }
            
        except asyncio.TimeoutError:
            logger.error(f"ç²¾ç¡®æµ‹é€Ÿè¶…æ—¶ (> 60ç§’)")
            return {
                "status": "timeout",
                "speed_mbps": 0,
                "message": "æµ‹é€Ÿè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•",
                "timestamp": datetime.now().isoformat()
            }
        except Exception as inner_err:
            logger.error(f"ç²¾ç¡®æµ‹é€Ÿä¸‹è½½å¤±è´¥: {inner_err}")
            # å¦‚æœæœ‰éƒ¨åˆ†ä¸‹è½½æ•°æ®ï¼Œè¿”å›éƒ¨åˆ†æˆåŠŸ
            if bytes_downloaded > 0 and download_time > 0:
                speed_mbps = (bytes_downloaded / (1024 * 1024)) / download_time
                return {
                    "status": "partial_success",
                    "speed_mbps": round(speed_mbps, 2),
                    "download_time_seconds": round(download_time, 2),
                    "traffic_consumed_mb": round(bytes_downloaded / (1024 * 1024), 2),
                    "message": f"éƒ¨åˆ†æµ‹è¯•: {speed_mbps:.1f} MB/s",
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "status": "error",
                    "speed_mbps": 0,
                    "message": f"æµ‹é€Ÿå¤±è´¥: {str(inner_err)[:50]}",
                    "timestamp": datetime.now().isoformat()
                }
            
    except Exception as e:
        logger.error(f"ç²¾ç¡®æµ‹é€Ÿå¼‚å¸¸: {e}")
        return {
            "status": "error",
            "speed_mbps": 0,
            "message": f"API é”™è¯¯: {str(e)[:50]}",
            "timestamp": datetime.now().isoformat()
        }

# ==================== å¼€å‘è°ƒè¯•API ====================

@app.get("/api/debug/nodes-file")
async def debug_nodes_file():
    """è·å–åŸå§‹èŠ‚ç‚¹æ–‡ä»¶å†…å®¹ï¼ˆè°ƒè¯•ç”¨ï¼‰"""
    try:
        nodes_file = Path("verified_nodes.json")
        if nodes_file.exists():
            return JSONResponse(
                content=json.loads(nodes_file.read_text(encoding='utf-8')),
                media_type="application/json"
            )
        return {"status": "file_not_found"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/debug/sync-state")
async def debug_sync_state():
    """è·å–åŒæ­¥çŠ¶æ€æ–‡ä»¶å†…å®¹ï¼ˆè°ƒè¯•ç”¨ï¼‰"""
    try:
        state_file = Path("sync_state.json")
        if state_file.exists():
            return JSONResponse(
                content=json.loads(state_file.read_text(encoding='utf-8')),
                media_type="application/json"
            )
        return {"status": "state_not_created_yet"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ==================== ä¸»ç¨‹åº ====================

if __name__ == "__main__":
    import uvicorn
    
    logger.info("=" * 60)
    logger.info("å¯åŠ¨viper-node-store APIæœåŠ¡")
    logger.info("=" * 60)
    
    uvicorn.run(
        "app_fastapi:app",
        host="0.0.0.0",
        port=8002,
        reload=False,
        log_level="info"
    )
