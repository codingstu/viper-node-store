#!/usr/bin/env python3
"""
SHADOW NEXUS - èŠ‚ç‚¹æ›´æ–°ç³»ç»Ÿ (é˜¿é‡Œäº‘å¤§é™†æµ‹é€Ÿç‰ˆ)
=====================================
æ¶æ„: GitHub Action (è°ƒåº¦) -> Aliyun FC Function (å¤§é™†æ¢é’ˆ) -> Target Nodes
ä¼˜åŠ¿: 100% è¿˜åŸå¤§é™†ç”¨æˆ·çœŸå®å»¶è¿Ÿä¸è¿é€šæ€§
"""

import asyncio
import aiohttp
import os
import json
import time
import re
from urllib.parse import urlparse
from datetime import datetime
from typing import List, Dict
from email.utils import formatdate

# =================== é…ç½®åŒºåŸŸ ===================

# ç¯å¢ƒå˜é‡ (å¿…é¡»åœ¨ GitHub Secrets ä¸­è®¾ç½®)
API_URL = os.environ.get("SHADOW_VIPER_API", "")  # ä½ çš„åç«¯ API åœ°å€
SUPABASE_URL = os.environ.get("SUPABASE_URL", "")  # Supabase URL
SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")  # Supabase Key

# å¤§é™†æµ‹é€Ÿï¼šé˜¿é‡Œäº‘å‡½æ•°è®¡ç®—
ALIYUN_FC_URL = os.environ.get("ALIYUN_FC_URL", "")

# å›å›½èŠ‚ç‚¹æµ‹é€Ÿï¼šCloudflare Workers
CLOUDFLARE_WORKER_URL = os.environ.get("CLOUDFLARE_WORKER_URL", "")

# è°ƒè¯•ï¼šæ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
print(f"ğŸ”§ [DEBUG] ALIYUN_FC_URL: {ALIYUN_FC_URL[:50] if ALIYUN_FC_URL else 'NOT SET'}...")
print(f"ğŸ”§ [DEBUG] CLOUDFLARE_WORKER_URL: {CLOUDFLARE_WORKER_URL[:50] if CLOUDFLARE_WORKER_URL else 'NOT SET'}...")


# =================== æ ¸å¿ƒé€»è¾‘ ===================

def extract_host_port(link: str) -> tuple:
    """
    ä»ä»£ç†é“¾æ¥ä¸­æå– host å’Œ port
    æ”¯æŒ: vless://, vmess://, trojan://, ss:// ç­‰
    """
    try:
        # é¦–å…ˆå°è¯•æ ‡å‡† URL è§£æ
        parsed = urlparse(link)
        host = parsed.hostname
        port = parsed.port
        
        if host and port:
            return host, port
        
        # å¤‡é€‰ï¼šä» netloc æ‰‹åŠ¨è§£æï¼ˆå¤„ç†éæ ‡å‡†æ ¼å¼ï¼‰
        netloc = parsed.netloc
        if '@' in netloc:
            netloc = netloc.split('@')[1]
        
        if ':' in netloc:
            parts = netloc.rsplit(':', 1)
            try:
                return parts[0], int(parts[1])
            except:
                pass
        
        # å¦‚æœæ˜¯ VMessï¼Œå°è¯•ä» base64 è§£æ
        if link.startswith('vmess://'):
            try:
                import base64
                encoded = link.replace('vmess://', '')
                decoded = base64.b64decode(encoded).decode('utf-8')
                vmess_json = json.loads(decoded)
                host = vmess_json.get('add')
                port = vmess_json.get('port')
                if host and port:
                    return host, int(port)
            except:
                pass
        
        return None, None
    except Exception as e:
        return None, None

async def fetch_nodes_from_api(region: str = 'mainland') -> List[Dict]:
    """
    æ­¥éª¤1: è·å–èŠ‚ç‚¹ (ä» SpiderFlow åç«¯çš„ API)
    region: 'mainland' (å¤§é™†) æˆ– 'overseas' (æµ·å¤–)
    """
    # ä¼˜å…ˆå°è¯•ä»æœ¬åœ° JSON æ–‡ä»¶è¯»å–
    try:
        with open('public/nodes.json', 'r', encoding='utf-8') as f:
            local_nodes = json.load(f)
            if isinstance(local_nodes, list) and len(local_nodes) > 0:
                print(f"âœ… [1/3] ä»æœ¬åœ°æ–‡ä»¶åŠ è½½èŠ‚ç‚¹ (åœ°åŒº: {region})")
                print(f"   ğŸ“¦ åŠ è½½æˆåŠŸ: {len(local_nodes)} ä¸ªèŠ‚ç‚¹")
                return local_nodes
    except FileNotFoundError:
        pass
    except Exception as e:
        print(f"âš ï¸ æœ¬åœ°æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    
    # æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œå°è¯•ä» API è·å–
    if not API_URL:
        print("âŒ é”™è¯¯: SHADOW_VIPER_API ç¯å¢ƒå˜é‡æœªè®¾ç½®")
        return []

    print(f"ğŸš€ [1/3] ä»è¿œç¨‹ API è·å–èŠ‚ç‚¹: {API_URL} (åœ°åŒº: {region})")

    headers = {
        "User-Agent": "ShadowNexus/Probe",
        "Accept": "application/json"
    }

    # å¢åŠ è¶…æ—¶æ—¶é—´
    timeout = aiohttp.ClientTimeout(total=180, connect=60, sock_read=120)
    
    max_retries = 3
    for attempt in range(max_retries):
        try:
            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.get(API_URL, headers=headers) as resp:
                    print(f"   ğŸ“¡ API å“åº”çŠ¶æ€: {resp.status}")
                    if resp.status == 200:
                        nodes = await resp.json()
                        print(f"   ğŸ“¦ è·å–æˆåŠŸ: {len(nodes)} ä¸ªåŸå§‹èŠ‚ç‚¹")
                        return nodes
                    else:
                        text = await resp.text()
                        print(f"   âŒ è·å–å¤±è´¥: {text[:100]}")
                        return []
        except Exception as e:
            print(f"   âŒ ç½‘ç»œå¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {type(e).__name__}")
            if attempt < max_retries - 1:
                print(f"   â³ ç­‰å¾… 5 ç§’åé‡è¯•...")
                await asyncio.sleep(5)
            else:
                print(f"   ğŸ” è°ƒè¯•ä¿¡æ¯: API_URL={API_URL[:60]}...")
                return []


async def test_nodes_via_aliyun(nodes: List[Dict]) -> List[Dict]:
    """
    æ­¥éª¤2: å‘é€ç»™é˜¿é‡Œäº‘è¿›è¡Œå¤§é™†æµ‹é€Ÿ
    å¦‚æœå¤±è´¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°æµ‹é€Ÿä½œä¸ºé™çº§æ–¹æ¡ˆ
    """
    if not ALIYUN_FC_URL:
        print("âŒ é”™è¯¯: ALIYUN_FC_URL æœªè®¾ç½®ï¼Œæ— æ³•æµ‹é€Ÿ")
        return []

    print(f"\nğŸš€ [2/3] å¯åŠ¨å¤§é™†æµ‹é€Ÿ (é˜¿é‡Œäº‘æ­å·/ä¸Šæµ·/åŒ—äº¬)...")

    valid_nodes = []
    # é˜¿é‡Œäº‘å‡½æ•°é™åˆ¶è¶…æ—¶ï¼Œå»ºè®®åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹ 15 ä¸ª
    batch_size = 15
    total_success = 0
    total_failed = 0

    async with aiohttp.ClientSession() as session:
        for i in range(0, len(nodes), batch_size):
            batch = nodes[i:i + batch_size]

            # æ„é€  Payloadï¼ˆåŒ…å«å¯†é’¥å’ŒèŠ‚ç‚¹åˆ—è¡¨ï¼‰
            payload_nodes = []
            for n in batch:
                # æå– host å’Œ port
                host = n.get('host')
                port = n.get('port')
                
                # å¦‚æœæ²¡æœ‰ host/portï¼Œå°è¯•ä» link å­—æ®µè§£æ
                if not host or not port:
                    link = n.get('link', '')
                    host, port = extract_host_port(link)
                
                # è·³è¿‡æ— æ³•è§£æçš„èŠ‚ç‚¹
                if not host or not port:
                    print(f"âš ï¸ æ— æ³•è§£æèŠ‚ç‚¹: {n.get('name', 'unknown')}")
                    continue
                
                # ç¡®ä¿ id å­˜åœ¨
                n_id = n.get("id") or n.get("name") or f"{host}:{port}"
                payload_nodes.append({
                    "id": n_id,
                    "host": host,
                    "port": int(port)
                })
            
            if not payload_nodes:
                print(f"âš ï¸ æ‰¹æ¬¡ {i // batch_size + 1} æ²¡æœ‰æœ‰æ•ˆèŠ‚ç‚¹")
                continue

            # å®Œæ•´çš„è¯·æ±‚ä½“ï¼šåªåŒ…å« nodesï¼ˆç§»é™¤è®¤è¯ï¼‰
            request_payload = {
                "nodes": payload_nodes
            }

            try:
                print(f"   ğŸ“¤ å‘é€æ‰¹æ¬¡ {i // batch_size + 1} ({len(payload_nodes)} ä¸ªèŠ‚ç‚¹)...")

                # æ„é€ è¯·æ±‚å¤´
                request_headers = {
                    "Content-Type": "application/json",
                    "Date": formatdate(timeval=None, localtime=False, usegmt=True)
                }

                async with session.post(
                        ALIYUN_FC_URL,
                        json=request_payload,
                        headers=request_headers,
                        timeout=20  # ç»™é˜¿é‡Œäº‘è¶³å¤Ÿçš„è¿è¡Œæ—¶é—´
                ) as resp:
                    if resp.status == 200:
                        results = await resp.json()
                        total_success += len([r for r in results if r.get('success')])
                        total_failed += len([r for r in results if not r.get('success')])

                        for res in results:
                            if not res['success']:
                                continue

                            # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹èŠ‚ç‚¹
                            # ä½¿ç”¨ ID æˆ– host:port åŒ¹é…
                            orig = next((x for x in batch if
                                         (x.get("id") == res['id'] or x.get("name") == res['id'] or f"{x.get('host', '')}:{x.get('port', '')}" == res['id'])), None)

                            if orig:
                                latency = res['latency']

                                # === å¤§é™†ä¼˜åŒ–çš„è¯„åˆ†é€»è¾‘ ===
                                # å¤§é™†è¿å¢ƒå¤–ï¼Œå»¶è¿Ÿé€šå¸¸è¾ƒé«˜ï¼Œè¯„åˆ†æ ‡å‡†éœ€æ”¾å®½
                                speed_score = 0
                                quality_score = 0

                                if latency < 50:  # æé€Ÿ (CN2/ä¸“çº¿)
                                    speed_score = 50
                                    quality_score = 95
                                elif latency < 100:  # ä¼˜ç§€ (äºšå¤ªç›´è¿)
                                    speed_score = 30
                                    quality_score = 85
                                elif latency < 200:  # æ­£å¸¸ (ç¾è¥¿ç›´è¿)
                                    speed_score = 10
                                    quality_score = 70
                                elif latency < 350:  # ä¸€èˆ¬ (æ™®é€šçº¿è·¯)
                                    speed_score = 3
                                    quality_score = 50
                                else:  # è¾ƒå·® (ç»•è·¯)
                                    speed_score = 1
                                    quality_score = 30

                                # æ›´æ–°èŠ‚ç‚¹æ•°æ®
                                orig['latency_ms'] = latency
                                orig['speed'] = speed_score
                                orig['quality_score'] = quality_score
                                orig['success_rate'] = 100
                                orig['updated_at'] = datetime.now().isoformat()

                                valid_nodes.append(orig)
                                print(f"     âœ… {orig.get('host', 'N/A')} | å»¶è¿Ÿ: {latency}ms (å¤§é™†çœŸå®)")
                    else:
                        error_text = await resp.text()
                        print(f"     âš ï¸ é˜¿é‡Œäº‘è¿”å›é”™è¯¯ {resp.status}: {error_text[:200]}")
                        
                        # å¦‚æœæ˜¯è®¤è¯é”™è¯¯ï¼Œæ‰“å°è¯¦ç»†ä¿¡æ¯ç”¨äºè¯Šæ–­
                        if resp.status == 401 or resp.status == 400:
                            try:
                                error_json = json.loads(error_text)
                                print(f"     ğŸ“‹ è¯¦ç»†é”™è¯¯: {json.dumps(error_json, ensure_ascii=False)}")
                            except:
                                pass

            except Exception as e:
                print(f"     âŒ æ‰¹æ¬¡è¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {str(e)}")

            # é¿å…è§¦å‘é¢‘ç‡é™åˆ¶
            await asyncio.sleep(0.5)

    # æŒ‰è´¨é‡æ’åº
    valid_nodes.sort(key=lambda x: x.get("quality_score", 0), reverse=True)
    print(f"âœ… æµ‹é€Ÿå®Œæˆ: {len(valid_nodes)} / {len(nodes)} ä¸ªèŠ‚ç‚¹åœ¨å¤§é™†å¯ç”¨ (æˆåŠŸ: {total_success}, å¤±è´¥: {total_failed})")
    return valid_nodes


async def test_nodes_via_cloudflare(nodes: List[Dict]) -> List[Dict]:
    """
    æ­¥éª¤2B: å‘é€ç»™ Cloudflare Workers è¿›è¡Œå›½å¤–æµ‹é€Ÿ (å›å›½èŠ‚ç‚¹)
    """
    if not CLOUDFLARE_WORKER_URL:
        print("âš ï¸ è­¦å‘Š: CLOUDFLARE_WORKER_URL æœªè®¾ç½®ï¼Œè·³è¿‡å›½å¤–æµ‹é€Ÿ")
        return []

    print(f"\nğŸš€ [2B/3] å¯åŠ¨å›½å¤–æµ‹é€Ÿ (Cloudflare Workers)...")

    valid_nodes = []
    batch_size = 15
    total_success = 0
    total_failed = 0

    async with aiohttp.ClientSession() as session:
        for i in range(0, len(nodes), batch_size):
            batch = nodes[i:i + batch_size]

            # æ„é€  Payload
            payload_nodes = []
            for n in batch:
                host = n.get('host')
                port = n.get('port')
                
                if not host or not port:
                    link = n.get('link', '')
                    host, port = extract_host_port(link)
                
                if not host or not port:
                    continue
                
                n_id = n.get("id") or n.get("name") or f"{host}:{port}"
                payload_nodes.append({
                    "id": n_id,
                    "host": host,
                    "port": int(port)
                })
            
            if not payload_nodes:
                continue

            request_payload = {
                "nodes": payload_nodes
            }

            try:
                print(f"   ğŸ“¤ å‘é€æ‰¹æ¬¡ {i // batch_size + 1} ({len(payload_nodes)} ä¸ªèŠ‚ç‚¹)...")

                request_headers = {
                    "Content-Type": "application/json",
                    "Date": formatdate(timeval=None, localtime=False, usegmt=True)
                }

                async with session.post(
                        CLOUDFLARE_WORKER_URL,
                        json=request_payload,
                        headers=request_headers,
                        timeout=20
                ) as resp:
                    if resp.status == 200:
                        results = await resp.json()
                        total_success += len([r for r in results if r.get('success')])
                        total_failed += len([r for r in results if not r.get('success')])

                        for res in results:
                            if not res['success']:
                                continue

                            orig = next((x for x in batch if
                                         (x.get("id") == res['id'] or x.get("name") == res['id'] or f"{x.get('host', '')}:{x.get('port', '')}" == res['id'])), None)

                            if orig:
                                latency = res['latency']

                                # === å›½å¤–ä¼˜åŒ–çš„è¯„åˆ†é€»è¾‘ ===
                                # å›½å¤–æµ‹é€Ÿå»¶è¿Ÿä¼šæ›´é«˜ï¼Œæ ‡å‡†æ”¾æ›´å®½
                                speed_score = 0
                                quality_score = 0

                                if latency < 100:  # æé€Ÿ (è·ç¦»è¿‘/ä¸“çº¿)
                                    speed_score = 50
                                    quality_score = 95
                                elif latency < 150:  # ä¼˜ç§€
                                    speed_score = 30
                                    quality_score = 85
                                elif latency < 250:  # æ­£å¸¸
                                    speed_score = 10
                                    quality_score = 70
                                elif latency < 400:  # ä¸€èˆ¬
                                    speed_score = 3
                                    quality_score = 50
                                else:  # è¾ƒå·®
                                    speed_score = 1
                                    quality_score = 30

                                orig['latency_ms'] = latency
                                orig['speed'] = speed_score
                                orig['quality_score'] = quality_score
                                orig['success_rate'] = 100
                                orig['updated_at'] = datetime.now().isoformat()
                                orig['test_via'] = 'cloudflare'  # æ ‡è®°æµ‹è¯•æ¥æº

                                valid_nodes.append(orig)
                                print(f"     âœ… {orig.get('host', 'N/A')} | å»¶è¿Ÿ: {latency}ms (å›½å¤–çœŸå®)")
                    else:
                        error_text = await resp.text()
                        print(f"     âš ï¸ Cloudflare è¿”å›é”™è¯¯ {resp.status}: {error_text[:200]}")

            except Exception as e:
                print(f"     âŒ æ‰¹æ¬¡è¯·æ±‚å¼‚å¸¸: {type(e).__name__}: {str(e)}")

            await asyncio.sleep(0.5)

    valid_nodes.sort(key=lambda x: x.get("quality_score", 0), reverse=True)
    print(f"âœ… å›½å¤–æµ‹é€Ÿå®Œæˆ: {len(valid_nodes)} / {len(nodes)} ä¸ªèŠ‚ç‚¹åœ¨å›½å¤–å¯ç”¨ (æˆåŠŸ: {total_success}, å¤±è´¥: {total_failed})")
    return valid_nodes


def save_to_supabase(nodes: List[Dict]):
    """
    æ­¥éª¤3: ä¿å­˜ç»“æœ (å«æ•´æ•°ä¿®å¤å’Œå»é‡)
    """
    if not SUPABASE_URL:
        return

    print(f"\nğŸš€ [3/3] ä¿å­˜è‡³æ•°æ®åº“...")
    try:
        from supabase import create_client
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

        data = []
        seen_ids = set()  # ç”¨äºå»é‡
        
        for i, node in enumerate(nodes):
            # æ„é€ å”¯ä¸€ID
            node_id = f"{node.get('host', 'unknown')}:{node.get('port', 'unknown')}"
            
            # è·³è¿‡é‡å¤çš„ID
            if node_id in seen_ids:
                print(f"âš ï¸ è·³è¿‡é‡å¤èŠ‚ç‚¹: {node_id}")
                continue
            
            seen_ids.add(node_id)

            data.append({
                "id": node_id,
                "content": node,
                "link": node.get("link", ""),  # æ·»åŠ  link å­—æ®µç›´æ¥åˆ°è¡¨ä¸­
                "is_free": i < 15,  # å‰15ä¸ªå…è´¹
                # ğŸŸ¢ ä¿®å¤: å¼ºåˆ¶è½¬æ•´æ•°ï¼Œè§£å†³ "20.0" æŠ¥é”™
                "speed": int(float(node.get("speed", 0))),
                "latency": int(node.get("latency_ms", 9999)),
                "updated_at": datetime.now().isoformat()
            })

        if not data:
            print("âš ï¸ æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜")
            return

        # åˆ†æ‰¹å†™å…¥
        batch_size = 50
        total_saved = 0
        for i in range(0, len(data), batch_size):
            batch = data[i:i + batch_size]
            try:
                supabase.table("nodes").upsert(batch).execute()
                total_saved += len(batch)
                print(f"  ğŸ“ æ‰¹æ¬¡ {i // batch_size + 1}: ä¿å­˜ {len(batch)} æ¡")
            except Exception as batch_error:
                print(f"  âš ï¸ æ‰¹æ¬¡ {i // batch_size + 1} ä¿å­˜å¤±è´¥: {batch_error}")

        print(f"ğŸ’¾ æˆåŠŸä¿å­˜ {total_saved} æ¡æ•°æ®")

    except Exception as e:
        print(f"âŒ æ•°æ®åº“ä¿å­˜å¤±è´¥: {type(e).__name__}: {e}")


async def main():
    # 1. è·å–åŸå§‹èŠ‚ç‚¹
    raw_nodes = await fetch_nodes_from_api()
    if not raw_nodes:
        print("âŒ æ— æ³•è·å–èŠ‚ç‚¹")
        return

    print(f"\nğŸ“Š èŠ‚ç‚¹åˆ†ç±»ç»Ÿè®¡:")
    print(f"   æ€»èŠ‚ç‚¹æ•°: {len(raw_nodes)}")
    
    # 2A. åˆ†ç±»å¤„ç†èŠ‚ç‚¹
    # ä¼˜å…ˆçº§: 
    # - å¦‚æœ country å­—æ®µå­˜åœ¨ï¼Œä½¿ç”¨å®ƒ
    # - å¦‚æœæ²¡æœ‰ï¼Œå°è¯•ä»å…¶ä»–å­—æ®µæ¨æ–­
    
    cn_nodes = []
    overseas_nodes = []
    
    for node in raw_nodes:
        country = node.get('country', '').upper()
        
        # å¤§é™†èŠ‚ç‚¹
        if country == 'CN':
            cn_nodes.append(node)
        # é¦™æ¸¯/å°æ¹¾/æ¾³é—¨ -> å½’ç±»ä¸ºå›½å¤–ï¼ˆéœ€è¦å›½å¤–æµ‹é€Ÿï¼‰
        elif country in ['HK', 'TW', 'MO']:
            overseas_nodes.append(node)
        # å…¶ä»–å›½å¤–èŠ‚ç‚¹
        elif country and country != 'CN':
            overseas_nodes.append(node)
        # æ²¡æœ‰å›½å®¶æ ‡ç­¾ï¼Œé»˜è®¤å½’ä¸ºå›½å¤–
        else:
            overseas_nodes.append(node)
    
    print(f"   ğŸ‡¨ğŸ‡³ å¤§é™†èŠ‚ç‚¹: {len(cn_nodes)}")
    print(f"   ğŸŒ å›½å¤–èŠ‚ç‚¹: {len(overseas_nodes)}")
    
    all_valid_nodes = []
    
    # 2B. å¤§é™†èŠ‚ç‚¹ï¼šä½¿ç”¨é˜¿é‡Œäº‘æµ‹é€Ÿ
    if cn_nodes:
        aliyun_results = await test_nodes_via_aliyun(cn_nodes)
        all_valid_nodes.extend(aliyun_results)
    
    # 2C. å›½å¤–èŠ‚ç‚¹ï¼šä½¿ç”¨ Cloudflare Workers æµ‹é€Ÿ
    if overseas_nodes:
        cf_results = await test_nodes_via_cloudflare(overseas_nodes)
        all_valid_nodes.extend(cf_results)
    
    # 3. ä¿å­˜æ‰€æœ‰ç»“æœ
    if all_valid_nodes:
        print(f"\nğŸ“¦ å…±æœ‰ {len(all_valid_nodes)} ä¸ªèŠ‚ç‚¹é€šè¿‡æµ‹é€Ÿï¼Œå³å°†ä¿å­˜...")
        save_to_supabase(all_valid_nodes)
    else:
        print("âš ï¸ æ²¡æœ‰èŠ‚ç‚¹é€šè¿‡æµ‹é€Ÿ")


if __name__ == "__main__":
    asyncio.run(main())