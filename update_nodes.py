#!/usr/bin/env python3
"""
SHADOW NEXUS - èŠ‚ç‚¹æ›´æ–°ä¸ä¸¥æ ¼æµ‹è¯•ç³»ç»Ÿ
=====================================
åŠŸèƒ½:
1. TCP ç«¯å£è¿é€šæ€§æµ‹è¯•
2. å¤šæ¬¡æµ‹è¯•å–å¹³å‡å»¶è¿Ÿ
3. ä¸¢åŒ…ç‡æ£€æµ‹ (è¿æ¥æˆåŠŸç‡)
4. å¼‚æ­¥å¹¶å‘æµ‹è¯•æé«˜æ•ˆç‡
5. ä¸¥æ ¼è¿‡æ»¤ä¸å¯ç”¨èŠ‚ç‚¹
6. æŒ‰å»¶è¿Ÿå’Œé€Ÿåº¦ç»¼åˆæ’åº
"""

import asyncio
import aiohttp
import socket
import time
import os
import json
import statistics
from datetime import datetime
from typing import Optional, Dict, List, Tuple
from concurrent.futures import ThreadPoolExecutor

# =================== é…ç½®åŒºåŸŸ ===================
# æµ‹è¯•é…ç½®
TEST_ROUNDS = 3          # æ¯ä¸ªèŠ‚ç‚¹æµ‹è¯•è½®æ•°
TCP_TIMEOUT = 5          # TCP è¿æ¥è¶…æ—¶ç§’æ•°
MAX_LATENCY_MS = 3000    # æœ€å¤§å¯æ¥å—å»¶è¿Ÿ (æ¯«ç§’)
MIN_SUCCESS_RATE = 0.6   # æœ€ä½æˆåŠŸç‡ (60%)
MAX_CONCURRENT = 50      # æœ€å¤§å¹¶å‘æµ‹è¯•æ•°

# ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
API_URL = os.environ.get("SHADOW_VIPER_API", "")
SUPABASE_URL = os.environ.get("SUPABASE_URL", "")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "")

# =================== æ ¸å¿ƒæµ‹è¯•å‡½æ•° ===================

def tcp_ping(host: str, port: int, timeout: float = TCP_TIMEOUT) -> Tuple[bool, float]:
    """
    TCP ç«¯å£è¿é€šæ€§æµ‹è¯•
    è¿”å›: (æ˜¯å¦æˆåŠŸ, å»¶è¿Ÿæ¯«ç§’)
    """
    try:
        start = time.perf_counter()
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        
        # å°è¯•è¿æ¥
        result = sock.connect_ex((host, int(port)))
        
        end = time.perf_counter()
        latency_ms = (end - start) * 1000
        
        sock.close()
        
        if result == 0:
            return (True, round(latency_ms, 2))
        else:
            return (False, -1)
            
    except socket.gaierror:
        # DNS è§£æå¤±è´¥
        return (False, -1)
    except socket.timeout:
        # è¿æ¥è¶…æ—¶
        return (False, -1)
    except Exception as e:
        return (False, -1)


async def test_node_async(node: Dict, executor: ThreadPoolExecutor) -> Optional[Dict]:
    """
    å¼‚æ­¥æµ‹è¯•å•ä¸ªèŠ‚ç‚¹
    è¿›è¡Œå¤šè½® TCP è¿é€šæ€§æµ‹è¯•ï¼Œè®¡ç®—å¹³å‡å»¶è¿Ÿå’ŒæˆåŠŸç‡
    """
    host = node.get("host", "")
    port = node.get("port", 0)
    
    if not host or not port:
        return None
    
    loop = asyncio.get_event_loop()
    results = []
    
    # å¤šè½®æµ‹è¯•
    for _ in range(TEST_ROUNDS):
        try:
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œ TCP ping (é¿å…é˜»å¡äº‹ä»¶å¾ªç¯)
            success, latency = await loop.run_in_executor(
                executor, tcp_ping, host, port, TCP_TIMEOUT
            )
            results.append((success, latency))
        except Exception:
            results.append((False, -1))
        
        # è½®æ¬¡é—´å°å»¶è¿Ÿï¼Œé¿å…è¢«è¯†åˆ«ä¸ºæ”»å‡»
        await asyncio.sleep(0.1)
    
    # ç»Ÿè®¡ç»“æœ
    success_count = sum(1 for r in results if r[0])
    success_rate = success_count / len(results)
    
    # è¿‡æ»¤: æˆåŠŸç‡å¤ªä½
    if success_rate < MIN_SUCCESS_RATE:
        print(f"  âŒ {host}:{port} - æˆåŠŸç‡è¿‡ä½ ({success_rate*100:.0f}%)")
        return None
    
    # è®¡ç®—æœ‰æ•ˆå»¶è¿Ÿ
    valid_latencies = [r[1] for r in results if r[0] and r[1] > 0]
    
    if not valid_latencies:
        print(f"  âŒ {host}:{port} - æ— æœ‰æ•ˆå»¶è¿Ÿæ•°æ®")
        return None
    
    avg_latency = statistics.mean(valid_latencies)
    min_latency = min(valid_latencies)
    max_latency = max(valid_latencies)
    
    # è®¡ç®—å»¶è¿ŸæŠ–åŠ¨ (ç¨³å®šæ€§æŒ‡æ ‡)
    jitter = max_latency - min_latency if len(valid_latencies) > 1 else 0
    
    # è¿‡æ»¤: å»¶è¿Ÿè¿‡é«˜
    if avg_latency > MAX_LATENCY_MS:
        print(f"  âš ï¸  {host}:{port} - å»¶è¿Ÿè¿‡é«˜ ({avg_latency:.0f}ms)")
        return None
    
    # æ ¹æ®å»¶è¿Ÿè®¡ç®—è´¨é‡åˆ†æ•° (ç”¨äºæ’åº)
    # åˆ†æ•° = 100 - (å»¶è¿Ÿè´¡çŒ® + æŠ–åŠ¨è´¡çŒ® + æˆåŠŸç‡è´¡çŒ®)
    latency_score = min(avg_latency / 30, 50)  # å»¶è¿Ÿè¶Šä½è¶Šå¥½, æœ€é«˜æ‰£50åˆ†
    jitter_score = min(jitter / 100, 20)        # æŠ–åŠ¨è¶Šå°è¶Šå¥½, æœ€é«˜æ‰£20åˆ†  
    rate_score = (1 - success_rate) * 30        # æˆåŠŸç‡è¶Šé«˜è¶Šå¥½, æœ€é«˜æ‰£30åˆ†
    quality_score = max(0, 100 - latency_score - jitter_score - rate_score)
    
    # æ ¹æ®è´¨é‡åˆ†æ•°ä¼°ç®—"é€Ÿåº¦" (MB/s) - ç”¨äºå‰ç«¯æ˜¾ç¤º
    # è¿™æ˜¯ä¸€ä¸ªåŸºäºå»¶è¿Ÿçš„ä¼°ç®—å€¼ï¼Œå®é™…é€Ÿåº¦éœ€è¦ä¸‹è½½æµ‹è¯•
    if avg_latency < 100:
        estimated_speed = round(10 + quality_score / 10, 2)
    elif avg_latency < 300:
        estimated_speed = round(5 + quality_score / 20, 2)
    elif avg_latency < 800:
        estimated_speed = round(2 + quality_score / 30, 2)
    else:
        estimated_speed = round(0.5 + quality_score / 50, 2)
    
    # æ„å»ºæµ‹è¯•ç»“æœ
    tested_node = node.copy()
    tested_node["speed"] = estimated_speed
    tested_node["latency_ms"] = round(avg_latency, 2)
    tested_node["jitter_ms"] = round(jitter, 2)
    tested_node["success_rate"] = round(success_rate * 100, 1)
    tested_node["quality_score"] = round(quality_score, 1)
    tested_node["tested_at"] = datetime.now().isoformat()
    
    status_icon = "ğŸŸ¢" if avg_latency < 300 else "ğŸŸ¡" if avg_latency < 800 else "ğŸŸ "
    print(f"  {status_icon} {host}:{port} - {avg_latency:.0f}ms, æˆåŠŸç‡{success_rate*100:.0f}%, è¯„åˆ†{quality_score:.0f}")
    
    return tested_node


async def test_all_nodes(nodes: List[Dict]) -> List[Dict]:
    """
    å¹¶å‘æµ‹è¯•æ‰€æœ‰èŠ‚ç‚¹
    """
    print(f"\nğŸ§ª å¼€å§‹ä¸¥æ ¼æµ‹è¯• {len(nodes)} ä¸ªèŠ‚ç‚¹...")
    print(f"   é…ç½®: {TEST_ROUNDS}è½®æµ‹è¯•, è¶…æ—¶{TCP_TIMEOUT}s, æœ€å¤§å»¶è¿Ÿ{MAX_LATENCY_MS}ms")
    print("-" * 60)
    
    # åˆ›å»ºçº¿ç¨‹æ± ç”¨äº TCP æµ‹è¯•
    executor = ThreadPoolExecutor(max_workers=MAX_CONCURRENT)
    
    # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(MAX_CONCURRENT)
    
    async def limited_test(node):
        async with semaphore:
            return await test_node_async(node, executor)
    
    # å¹¶å‘æµ‹è¯•æ‰€æœ‰èŠ‚ç‚¹
    tasks = [limited_test(node) for node in nodes]
    results = await asyncio.gather(*tasks)
    
    executor.shutdown(wait=False)
    
    # è¿‡æ»¤æ‰ None (æµ‹è¯•å¤±è´¥çš„èŠ‚ç‚¹)
    valid_nodes = [n for n in results if n is not None]
    
    # æŒ‰è´¨é‡åˆ†æ•°æ’åº (é«˜åˆ†åœ¨å‰)
    valid_nodes.sort(key=lambda x: x.get("quality_score", 0), reverse=True)
    
    print("-" * 60)
    print(f"âœ… æµ‹è¯•å®Œæˆ: {len(valid_nodes)}/{len(nodes)} ä¸ªèŠ‚ç‚¹é€šè¿‡")
    
    return valid_nodes


async def fetch_nodes_from_api() -> List[Dict]:
    """
    ä» API è·å–åŸå§‹èŠ‚ç‚¹åˆ—è¡¨
    """
    if not API_URL:
        raise ValueError("SHADOW_VIPER_API ç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    print(f"ğŸš€ æ­£åœ¨ä» API æ‹‰å–èŠ‚ç‚¹...")
    
    async with aiohttp.ClientSession() as session:
        async with session.get(API_URL, timeout=aiohttp.ClientTimeout(total=120)) as resp:
            if resp.status != 200:
                raise Exception(f"API è¯·æ±‚å¤±è´¥: {resp.status}")
            
            nodes = await resp.json()
            print(f"ğŸ“¦ è·å–åˆ° {len(nodes)} ä¸ªåŸå§‹èŠ‚ç‚¹")
            return nodes


def save_to_supabase(nodes: List[Dict]):
    """
    å°†æµ‹è¯•é€šè¿‡çš„èŠ‚ç‚¹ä¿å­˜åˆ° Supabase
    """
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âš ï¸  Supabase é…ç½®ç¼ºå¤±ï¼Œè·³è¿‡æ•°æ®åº“ä¿å­˜")
        return
    
    try:
        from supabase import create_client, Client
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
        
        data_to_upsert = []
        
        for index, node in enumerate(nodes):
            node_id = f"{node['host']}:{node['port']}"
            
            # å‰ 15 ä¸ªé«˜è´¨é‡èŠ‚ç‚¹ä¸ºå…è´¹
            is_free = index < 15
            
            data_to_upsert.append({
                "id": node_id,
                "content": node,
                "is_free": is_free,
                "speed": int(node.get("speed", 0)),
                "latency": int(node.get("latency_ms", 9999)),
                "updated_at": datetime.now().isoformat()
            })
        
        # æ‰¹é‡å†™å…¥
        if data_to_upsert:
            batch_size = 100
            for i in range(0, len(data_to_upsert), batch_size):
                batch = data_to_upsert[i:i+batch_size]
                supabase.table("nodes").upsert(batch).execute()
            
            print(f"ğŸ’¾ Supabase æ›´æ–°æˆåŠŸ: {len(data_to_upsert)} æ¡æ•°æ®")
            
    except ImportError:
        print("âš ï¸  supabase æ¨¡å—æœªå®‰è£…ï¼Œè·³è¿‡æ•°æ®åº“ä¿å­˜")
    except Exception as e:
        print(f"âŒ Supabase ä¿å­˜å¤±è´¥: {e}")


def save_public_json(nodes: List[Dict], count: int = 5):
    """
    ç”Ÿæˆå…¬å¼€çš„èŠ‚ç‚¹ JSON æ–‡ä»¶ (ä»…å«å°‘é‡é¢„è§ˆèŠ‚ç‚¹)
    """
    os.makedirs("public", exist_ok=True)
    
    # å–å‰ N ä¸ªæœ€ä¼˜èŠ‚ç‚¹ä½œä¸ºè¯•ç”¨
    safe_nodes = []
    for node in nodes[:count]:
        # åˆ›å»ºç®€åŒ–ç‰ˆæœ¬ (éšè—æµ‹è¯•ç»†èŠ‚)
        safe_node = {
            "protocol": node.get("protocol"),
            "host": node.get("host"),
            "port": node.get("port"),
            "country": node.get("country"),
            "speed": node.get("speed"),
            "name": node.get("name"),
            "link": node.get("link")
        }
        safe_nodes.append(safe_node)
    
    with open("public/nodes.json", "w", encoding="utf-8") as f:
        json.dump(safe_nodes, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ›¡ï¸  public/nodes.json å·²æ›´æ–° ({len(safe_nodes)} ä¸ªè¯•ç”¨èŠ‚ç‚¹)")


def generate_report(original_count: int, valid_nodes: List[Dict]):
    """
    ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š èŠ‚ç‚¹æµ‹è¯•æŠ¥å‘Š")
    print("=" * 60)
    print(f"  åŸå§‹èŠ‚ç‚¹æ•°:   {original_count}")
    print(f"  é€šè¿‡æµ‹è¯•æ•°:   {len(valid_nodes)}")
    print(f"  è¿‡æ»¤ç‡:       {(1 - len(valid_nodes)/max(original_count,1))*100:.1f}%")
    
    if valid_nodes:
        latencies = [n.get("latency_ms", 0) for n in valid_nodes]
        scores = [n.get("quality_score", 0) for n in valid_nodes]
        
        print(f"\n  ğŸ“ˆ å»¶è¿Ÿç»Ÿè®¡:")
        print(f"     æœ€ä½: {min(latencies):.0f}ms")
        print(f"     æœ€é«˜: {max(latencies):.0f}ms")
        print(f"     å¹³å‡: {statistics.mean(latencies):.0f}ms")
        
        print(f"\n  â­ è´¨é‡è¯„åˆ†:")
        print(f"     æœ€é«˜: {max(scores):.1f}")
        print(f"     å¹³å‡: {statistics.mean(scores):.1f}")
        
        # æŒ‰åœ°åŒºç»Ÿè®¡
        countries = {}
        for n in valid_nodes:
            c = n.get("country", "UNK")
            countries[c] = countries.get(c, 0) + 1
        
        print(f"\n  ğŸŒ åœ°åŒºåˆ†å¸ƒ:")
        for c, count in sorted(countries.items(), key=lambda x: -x[1])[:5]:
            print(f"     {c}: {count} ä¸ª")
    
    print("=" * 60 + "\n")


async def main():
    """
    ä¸»å…¥å£
    """
    print("\n" + "ğŸ”¥" * 30)
    print("   SHADOW NEXUS - èŠ‚ç‚¹ä¸¥æ ¼æµ‹è¯•ç³»ç»Ÿ")
    print("ğŸ”¥" * 30 + "\n")
    
    start_time = time.time()
    
    try:
        # 1. è·å–åŸå§‹èŠ‚ç‚¹
        raw_nodes = await fetch_nodes_from_api()
        original_count = len(raw_nodes)
        
        if not raw_nodes:
            print("âŒ æ— èŠ‚ç‚¹æ•°æ®")
            return
        
        # 2. ä¸¥æ ¼æµ‹è¯•æ‰€æœ‰èŠ‚ç‚¹
        valid_nodes = await test_all_nodes(raw_nodes)
        
        if not valid_nodes:
            print("âŒ æ‰€æœ‰èŠ‚ç‚¹æµ‹è¯•å¤±è´¥")
            return
        
        # 3. ä¿å­˜åˆ° Supabase
        save_to_supabase(valid_nodes)
        
        # 4. ç”Ÿæˆå…¬å¼€ JSON
        save_public_json(valid_nodes, count=5)
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        generate_report(original_count, valid_nodes)
        
        elapsed = time.time() - start_time
        print(f"â±ï¸  æ€»è€—æ—¶: {elapsed:.1f} ç§’")
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        exit(1)


if __name__ == "__main__":
    asyncio.run(main())
