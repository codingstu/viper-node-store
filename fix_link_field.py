#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç´§æ€¥ä¿®å¤ï¼šSupabase nodes è¡¨æ·»åŠ  link å­—æ®µå¹¶ä» SpiderFlow åŒæ­¥

ç›®çš„ï¼š
1. åœ¨ Supabase nodes è¡¨ä¸­æ·»åŠ  link å­—ç¬¦å­—æ®µ
2. ä» SpiderFlow åç«¯è·å–å®Œæ•´çš„èŠ‚ç‚¹æ•°æ®ï¼ˆåŒ…å« linkï¼‰
3. æ›´æ–° Supabase ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹
"""

import os
import sys
import json
import requests
from datetime import datetime
from typing import List, Dict

# é…ç½®
SPIDERFLOW_API = "http://localhost:8001"
SUPABASE_URL = os.environ.get("SUPABASE_URL", "https://hnlkwtkxbqiakeyienok.supabase.co")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY", "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImhubGt3dGt4YnFpYWtleWllbm9rIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NjY5MDQwNTksImV4cCI6MjA4MjQ4MDA1OX0.Xg9vQdUfBdUW-IJaomEIRGsX6tB_k2grhrF4dm_aNME")

def step1_add_link_field_to_supabase():
    """
    æ­¥éª¤1: åœ¨ Supabase ä¸­æ·»åŠ  link å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    
    ä½¿ç”¨ Supabase REST API æˆ– SQL ç¼–è¾‘å™¨
    """
    print("ğŸ“ æ­¥éª¤1: ç¡®ä¿ Supabase nodes è¡¨æœ‰ link å­—æ®µ...")
    print("   ğŸ’¡ åœ¨ Supabase SQL Editor ä¸­è¿è¡Œ:")
    print("""
    -- å¦‚æœ link å­—æ®µä¸å­˜åœ¨ï¼Œæ·»åŠ å®ƒ
    ALTER TABLE IF EXISTS nodes 
    ADD COLUMN IF NOT EXISTS link TEXT DEFAULT '';
    
    -- åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
    CREATE INDEX IF NOT EXISTS idx_nodes_link ON nodes(link);
    """)
    print("   âœ… è¯·åœ¨ Supabase æ§åˆ¶å°æ‰§è¡Œä¸Šè¿° SQL")

def step2_fetch_nodes_from_spiderflow():
    """
    æ­¥éª¤2: ä» SpiderFlow è·å–å®Œæ•´èŠ‚ç‚¹æ•°æ®
    """
    print("\nğŸ”„ æ­¥éª¤2: ä» SpiderFlow è·å–èŠ‚ç‚¹æ•°æ®...")
    try:
        response = requests.get(f"{SPIDERFLOW_API}/api/nodes", timeout=10)
        if response.status_code != 200:
            print(f"âŒ SpiderFlow æ— å“åº” (çŠ¶æ€ç  {response.status_code})")
            return []
        
        nodes = response.json()
        print(f"âœ… æˆåŠŸè·å– {len(nodes)} ä¸ªèŠ‚ç‚¹")
        
        # éªŒè¯ link å­—æ®µ
        nodes_with_link = sum(1 for n in nodes if n.get('link'))
        nodes_without_link = len(nodes) - nodes_with_link
        print(f"   ğŸ“Š æœ‰ link å­—æ®µ: {nodes_with_link}")
        print(f"   âš ï¸  ç¼ºå°‘ link å­—æ®µ: {nodes_without_link}")
        
        return nodes
    except Exception as e:
        print(f"âŒ è·å–èŠ‚ç‚¹å¤±è´¥: {e}")
        return []

def step3_update_supabase_nodes(nodes: List[Dict]):
    """
    æ­¥éª¤3: æ›´æ–° Supabase ä¸­çš„èŠ‚ç‚¹æ•°æ®
    """
    if not nodes:
        print("\nâš ï¸ æ²¡æœ‰èŠ‚ç‚¹æ•°æ®éœ€è¦æ›´æ–°")
        return
    
    print(f"\nğŸ’¾ æ­¥éª¤3: æ›´æ–° Supabase ä¸­çš„ {len(nodes)} ä¸ªèŠ‚ç‚¹...")
    
    try:
        from supabase import create_client
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        
        # å‡†å¤‡æ•°æ®
        updates = []
        for node in nodes:
            updates.append({
                "id": f"{node.get('host', 'unknown')}:{node.get('port', 'unknown')}",
                "link": node.get('link', ''),  # è¿™æ˜¯å…³é”®ï¼
                "content": node,  # ä¿ç•™å®Œæ•´å†…å®¹
                "updated_at": datetime.now().isoformat()
            })
        
        # åˆ†æ‰¹æ›´æ–°
        batch_size = 50
        for i in range(0, len(updates), batch_size):
            batch = updates[i:i + batch_size]
            try:
                result = supabase.table("nodes").upsert(batch).execute()
                print(f"  âœ… æ‰¹æ¬¡ {i // batch_size + 1}: æ›´æ–° {len(batch)} æ¡")
            except Exception as e:
                print(f"  âŒ æ‰¹æ¬¡ {i // batch_size + 1} å¤±è´¥: {e}")
        
        print(f"\nâœ… å®Œæˆï¼å·²æ›´æ–° {len(updates)} ä¸ªèŠ‚ç‚¹")
        
    except ImportError:
        print("âŒ supabase åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install supabase")
    except Exception as e:
        print(f"âŒ æ›´æ–°å¤±è´¥: {e}")

def step4_verify():
    """
    æ­¥éª¤4: éªŒè¯æ•°æ®æ˜¯å¦æ­£ç¡®åŒæ­¥
    """
    print("\nğŸ” æ­¥éª¤4: éªŒè¯æ•°æ®åŒæ­¥...")
    try:
        # æŸ¥è¯¢å‰ç«¯ API
        response = requests.get("http://localhost:8002/api/nodes?limit=3", timeout=5)
        if response.status_code == 200:
            nodes = response.json()
            print(f"âœ… å‰ç«¯ API è¿”å› {len(nodes)} ä¸ªèŠ‚ç‚¹")
            for node in nodes[:3]:
                link = node.get('link', '')
                print(f"   â€¢ {node.get('name', 'N/A')}: link={'âœ…' if link else 'âŒ'}")
        else:
            print(f"âš ï¸ å‰ç«¯ API è¿”å›çŠ¶æ€ç  {response.status_code}")
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")

def main():
    """ä¸»ç¨‹åº"""
    print("=" * 60)
    print("ğŸ”§ Supabase nodes è¡¨ link å­—æ®µä¿®å¤")
    print("=" * 60)
    
    # æ­¥éª¤1ï¼šæ·»åŠ å­—æ®µ
    step1_add_link_field_to_supabase()
    
    # æ­¥éª¤2ï¼šè·å–æ•°æ®
    nodes = step2_fetch_nodes_from_spiderflow()
    
    # æ­¥éª¤3ï¼šæ›´æ–°æ•°æ®åº“
    if nodes:
        step3_update_supabase_nodes(nodes)
    
    # æ­¥éª¤4ï¼šéªŒè¯
    step4_verify()
    
    print("\n" + "=" * 60)
    print("âœ… ä¿®å¤å®Œæˆï¼")
    print("=" * 60)
    print("\nåç»­æ­¥éª¤:")
    print("1. åœ¨ Supabase SQL Editor ä¸­æ‰§è¡Œ ALTER TABLE SQL")
    print("2. åˆ·æ–°å‰ç«¯é¡µé¢ (Cmd+Shift+R)")
    print("3. æ‰€æœ‰èŠ‚ç‚¹çš„å¤åˆ¶å’ŒäºŒç»´ç æŒ‰é’®åº”è¯¥ç°åœ¨å¯ç”¨")

if __name__ == "__main__":
    main()
